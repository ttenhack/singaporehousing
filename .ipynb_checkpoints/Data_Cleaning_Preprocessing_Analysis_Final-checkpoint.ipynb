{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "<hr>\n",
    "The libraries used are pandas, numpy, seaborn, Counter, matplotlib, axes3d, linearregression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import sklearn\n",
    "from collections import Counter\n",
    "\n",
    "# Visualization\n",
    "%matplotlib inline \n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('png2x','pdf')\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from IPython.display import IFrame\n",
    "import geocoder\n",
    "\n",
    "# machine learning library\n",
    "from sklearn import datasets, linear_model, cross_validation\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "#import xgboost as xgb\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# other\n",
    "import time\n",
    "\n",
    "pd.options.mode.chained_assignment = None #SettingWithCopyWarning for confusing chained assignment disabled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Data Acquisition\n",
    "<hr>\n",
    "The data for this report is acquired from the Singapore government website [1]. Data are collected from the period 1990 until January 2018. The data is provided in four seperate files, which will be merged into Python. The third file (> 20 MB) was seperated into periods of 2006-2012 and 2012-2014. This was necessary to make use of the Github repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "data1 = pd.read_csv('sg-resale-flat-prices-1990-1999.csv', sep =',')\n",
    "data2 = pd.read_csv('sg-resale-flat-prices-2000-2005.csv', sep =',')\n",
    "data3 = pd.read_csv('sg-resale-flat-prices-2006-2012.csv', sep =',')\n",
    "data4 = pd.read_csv('sg-resale-flat-prices-2012-2014.csv', sep =',')\n",
    "data5 = pd.read_csv('sg-resale-flat-prices-2014-2018.csv', sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training data = (58631, 10)\n"
     ]
    }
   ],
   "source": [
    "data5 = data5.drop('remaining_lease',1)\n",
    "print('Number of training data =', data5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training data = (768629, 10)\n"
     ]
    }
   ],
   "source": [
    "#concatenate dataset\n",
    "sets = [data1, data2, data3, data4, data5]\n",
    "data = pd.concat(sets)\n",
    "print('Number of training data =', data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Cleaning and Preprocessing the Dataset\n",
    "<hr>\n",
    "The cleaning and preprocessing section are divided into four sections, namely cleaning, encoding, feature engineering and one hot encoding.\n",
    "\n",
    "### 3.1 Data Cleaning\n",
    "During the exploration, there are some cleaning that should be performed. First, the flat types consist of eight types, which should be seven types instead. The flat type \"Multi Generation\" has a unique value with a space in between and one with a hyphen. Second, the flat models consist of 32 models, which should be 21 instead. This is also because of the capital usage. These doubles are removed by cleaning the data. Third, some storey range values in data set 4 are not correct. In the exploration, we have research the difference and since *** these values will be too different, these data points have been removed from the data set. Fourth, the feature \"month\" consists of sales year and sales month, e.g. 1990-01. To include the years and months in the model, this variable will be seperated to a variable called sales year and a variable called sales month. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Flat Type Count: 7\n",
      "Flat Type \n",
      "4 ROOM              285136\n",
      "3 ROOM              258482\n",
      "5 ROOM              156260\n",
      "EXECUTIVE            58177\n",
      "2 ROOM                8859\n",
      "1 ROOM                1246\n",
      "MULTI GENERATION       469\n",
      "Name: flat_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None #SettingWithCopyWarning for confusing chained assignment disabled\n",
    "\n",
    "#remove doubles\n",
    "data['flat_type'][data['flat_type'] == 'MULTI-GENERATION'] = 'MULTI GENERATION'\n",
    "\n",
    "#flat_type count\n",
    "count_flat_type = data['flat_type'].nunique()\n",
    "print(\"Total Flat Type Count:\", count_flat_type)\n",
    "flat_type_count = data['flat_type'].value_counts()\n",
    "print(\"Flat Type \\n\" +str(flat_type_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Flat Model Count: 21\n",
      "Flat Model Count \n",
      "Model A                   208633\n",
      "Improved                  202602\n",
      "New Generation            169643\n",
      "Simplified                 51604\n",
      "Standard                   38234\n",
      "Premium Apartment          28886\n",
      "Maisonette                 25136\n",
      "Apartment                  19745\n",
      "Apertment                   9901\n",
      "Model A2                    8382\n",
      "Adjoined flat               1913\n",
      "Model A-Maisonette          1784\n",
      "Terrace                      609\n",
      "DBSS                         601\n",
      "Multi Generation             469\n",
      "Type S1                      183\n",
      "Improved-Maisonette          105\n",
      "Type S2                       80\n",
      "Premium Maisonette            75\n",
      "2-room                        38\n",
      "Premium Apartment Loft         6\n",
      "Name: flat_model, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#remove doubles\n",
    "data['flat_model'][data['flat_model'] == 'MODEL A'] = 'Model A'\n",
    "data['flat_model'][data['flat_model'] == 'IMPROVED'] = 'Improved'\n",
    "data['flat_model'][data['flat_model'] == 'NEW GENERATION'] = 'New Generation'\n",
    "data['flat_model'][data['flat_model'] == 'PREMIUM APARTMENT'] = 'Premium Apartment'\n",
    "data['flat_model'][data['flat_model'] == 'SIMPLIFIED'] = 'Simplified'\n",
    "data['flat_model'][data['flat_model'] == 'STANDARD'] = 'Standard'\n",
    "data['flat_model'][data['flat_model'] == 'APARTMENT'] = 'Apertment'\n",
    "data['flat_model'][data['flat_model'] == 'MAISONETTE'] = 'Maisonette'\n",
    "data['flat_model'][data['flat_model'] == 'ADJOINED FLAT'] = 'Adjoined flat'\n",
    "data['flat_model'][data['flat_model'] == 'MODEL A-MAISONETTE'] = 'Model A-Maisonette'\n",
    "data['flat_model'][data['flat_model'] == 'TERRACE'] = 'Terrace'\n",
    "data['flat_model'][data['flat_model'] == 'MULTI GENERATION'] = 'Multi Generation'\n",
    "data['flat_model'][data['flat_model'] == 'IMPROVED-MAISONETTE'] = 'Improved-Maisonette'\n",
    "data['flat_model'][data['flat_model'] == '2-ROOM'] = '2-room'\n",
    "\n",
    "#flat_model count\n",
    "count_flat_model = data['flat_model'].nunique()\n",
    "print(\"Total Flat Model Count:\", count_flat_model)\n",
    "flat_model_count = data['flat_model'].value_counts()\n",
    "print(\"Flat Model Count \\n\" +str(flat_model_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Storey Range Count: 17\n",
      "Storey Range Count \n",
      "04 TO 06    196169\n",
      "07 TO 09    177012\n",
      "01 TO 03    158446\n",
      "10 TO 12    149470\n",
      "13 TO 15     46780\n",
      "16 TO 18     16906\n",
      "19 TO 21      8337\n",
      "22 TO 24      5233\n",
      "25 TO 27      2100\n",
      "28 TO 30       788\n",
      "34 TO 36       151\n",
      "31 TO 33       151\n",
      "37 TO 39       148\n",
      "40 TO 42        73\n",
      "46 TO 48        11\n",
      "43 TO 45        11\n",
      "49 TO 51         5\n",
      "Name: storey_range, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#remove storey range outliers\n",
    "#data = data.ix[data['storey_range'].isin(['01 TO 05','06 TO 10','11 TO 15','16 TO 20','21 TO 25','26 TO 30','31 TO 35','36 TO 40'])]\n",
    "data = data.loc[data['storey_range'].isin(['01 TO 03','04 TO 06','07 TO 09','10 TO 12','13 TO 15','16 TO 18','19 TO 21','22 TO 24','25 TO 27','28 TO 30','31 TO 33','34 TO 36','37 TO 39','40 TO 42','43 TO 45','46 TO 48','49 TO 51'])]\n",
    "\n",
    "#storey range count\n",
    "count_storey_range = data['storey_range'].nunique()\n",
    "print(\"Total Storey Range Count:\", count_storey_range)\n",
    "storey_range_count = data['storey_range'].value_counts()\n",
    "print(\"Storey Range Count \\n\" +str(storey_range_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#add sales year variable\n",
    "if ('sales_year' not in data.columns):\n",
    "    data.insert(1,'sales_year',(pd.DatetimeIndex(data['month']).year))\n",
    "\n",
    "#add sales year variable\n",
    "if ('sales_month' not in data.columns):\n",
    "    data.insert(1,'sales_month',(pd.DatetimeIndex(data['month']).month))\n",
    "    \n",
    "#add sales year variable\n",
    "if ('month' in data.columns):\n",
    "    del data['month']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that two variables are not going to be used, which are respectively block and street name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales_month</th>\n",
       "      <th>sales_year</th>\n",
       "      <th>town</th>\n",
       "      <th>flat_type</th>\n",
       "      <th>storey_range</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>flat_model</th>\n",
       "      <th>lease_commence_date</th>\n",
       "      <th>resale_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>1 ROOM</td>\n",
       "      <td>10 TO 12</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Improved</td>\n",
       "      <td>1977</td>\n",
       "      <td>9000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>1 ROOM</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Improved</td>\n",
       "      <td>1977</td>\n",
       "      <td>6000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>1 ROOM</td>\n",
       "      <td>10 TO 12</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Improved</td>\n",
       "      <td>1977</td>\n",
       "      <td>8000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>1 ROOM</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Improved</td>\n",
       "      <td>1977</td>\n",
       "      <td>6000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>73.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>1976</td>\n",
       "      <td>47200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sales_month  sales_year        town flat_type storey_range  floor_area_sqm  \\\n",
       "0            1        1990  ANG MO KIO    1 ROOM     10 TO 12            31.0   \n",
       "1            1        1990  ANG MO KIO    1 ROOM     04 TO 06            31.0   \n",
       "2            1        1990  ANG MO KIO    1 ROOM     10 TO 12            31.0   \n",
       "3            1        1990  ANG MO KIO    1 ROOM     07 TO 09            31.0   \n",
       "4            1        1990  ANG MO KIO    3 ROOM     04 TO 06            73.0   \n",
       "\n",
       "       flat_model  lease_commence_date  resale_price  \n",
       "0        Improved                 1977        9000.0  \n",
       "1        Improved                 1977        6000.0  \n",
       "2        Improved                 1977        8000.0  \n",
       "3        Improved                 1977        6000.0  \n",
       "4  New Generation                 1976       47200.0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove unnecessary variables\n",
    "data = data.drop('block',1)\n",
    "data = data.drop('street_name',1)\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Encoding\n",
    "When using categorical data, strings are not able to be interpreted by algorithms. Therefore, these values needs to be translated to a numerical value. For example, the towns in the dataset will be translated to $1,2,…,n$. Since there are rows in our dataset containing characters. These rows (town, flat type, flat model and storey range) are transformed into dummy variables to clarify their levels, with other words, to quantify the qualitative data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that data.copy() is used to make a copy of data, which will be used for analysis\n",
    "data_enc = data.copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummies for town\n",
    "town_array = np.unique(data['town'])\n",
    "n = len(town_array)\n",
    "\n",
    "for i in range(0,n):\n",
    "    data_enc['town'][data['town'] == town_array[i]] = i+1\n",
    "\n",
    "#count_town = data['town'].nunique()\n",
    "#print(\"Total Town Count:\", count_town)\n",
    "#town_count = data['town'].value_counts()\n",
    "#print(\"Town Count \\n\" +str(town_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummies for flat types\n",
    "data_enc['flat_type'][data.flat_type == '1 ROOM'] = 1\n",
    "data_enc['flat_type'][data.flat_type == '2 ROOM'] = 2\n",
    "data_enc['flat_type'][data.flat_type == '3 ROOM'] = 3\n",
    "data_enc['flat_type'][data.flat_type == '4 ROOM'] = 4\n",
    "data_enc['flat_type'][data.flat_type == '5 ROOM'] = 5\n",
    "data_enc['flat_type'][data.flat_type == 'MULTI GENERATION'] = 6\n",
    "data_enc['flat_type'][data.flat_type == 'EXECUTIVE'] = 7\n",
    "\n",
    "#flat_type_count = data['flat_type'].value_counts()\n",
    "#print(\"Flat Type \\n\" +str(flat_type_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummies for storey ranges \n",
    "storey_range_array = np.unique(data['storey_range'])\n",
    "n = len(storey_range_array)\n",
    "\n",
    "for i in range(0,n):\n",
    "    data_enc['storey_range'][data['storey_range'] == storey_range_array[i]] = i+1\n",
    "\n",
    "#count_storey_range = data['storey_range'].nunique()\n",
    "#print(\"Total Storey Range Count:\", count_storey_range)\n",
    "#storey_range_count = data['storey_range'].value_counts()\n",
    "#print(\"Storey Range Count \\n\" +str(storey_range_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummies for flat models\n",
    "flat_model_array = np.unique(data['flat_model'])\n",
    "n = len(flat_model_array)\n",
    "\n",
    "for i in range(0,n):\n",
    "    data_enc['flat_model'][data['flat_model'] == flat_model_array[i]] = i+1\n",
    "\n",
    "#count_flat_model = data['flat_model'].nunique()\n",
    "#print(\"Total Flat Model Count:\", count_flat_model)\n",
    "#flat_model_count = data['flat_model'].value_counts()\n",
    "#print(\"Flat Model Count \\n\" +str(flat_model_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales_month</th>\n",
       "      <th>sales_year</th>\n",
       "      <th>town</th>\n",
       "      <th>flat_type</th>\n",
       "      <th>storey_range</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>flat_model</th>\n",
       "      <th>lease_commence_date</th>\n",
       "      <th>resale_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1977</td>\n",
       "      <td>9000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1977</td>\n",
       "      <td>6000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1977</td>\n",
       "      <td>8000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1977</td>\n",
       "      <td>6000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>73.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1976</td>\n",
       "      <td>47200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sales_month  sales_year  town  flat_type  storey_range  floor_area_sqm  \\\n",
       "0            1        1990     1          1             4            31.0   \n",
       "1            1        1990     1          1             2            31.0   \n",
       "2            1        1990     1          1             4            31.0   \n",
       "3            1        1990     1          1             3            31.0   \n",
       "4            1        1990     1          3             2            73.0   \n",
       "\n",
       "   flat_model  lease_commence_date  resale_price  \n",
       "0           6                 1977        9000.0  \n",
       "1           6                 1977        6000.0  \n",
       "2           6                 1977        8000.0  \n",
       "3           6                 1977        6000.0  \n",
       "4          13                 1976       47200.0  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_enc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 One Hot Encoding (Categorical Data)\n",
    "Label encoding is a traditional way of translating strings into numerical values. The disadvantage of this method is the fact that algorithms might misinterpret these values. A higher town value does not necessarily mean that it has the potential of having higher resale prices.\n",
    "\n",
    "To cope with this problem, the one hot encoding approach is utilised. Instead of giving a numerical value, new columns are created per feature value. Continuing with the town example, this would mean that every town would have a new column. When the datapoint is part of this value, it will receive a $1$, whilst the other values receive a $0$ in this column. Therefore, it can be considered as a boolean solution for the feature values; either it is part of the value (True) or it is not (False). The disadvantage of the method is the fact that a significant amount of columns will be added to the dataset.\n",
    "\n",
    "To use the one hot encoding approach, the Panda feature get_dummies is used. This is similar to the LabelBinarizer function used in the Scikit-learn package. We chose for the pandas approach as our data was already converted to a pandas DataFrame. One hot encoding are used for the following features: town/area, flat type, flat model and storey range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that data.copy() is used to make a copy of data, which will be used for analysis\n",
    "data_henc = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding for town\n",
    "dummies = pd.get_dummies(data_henc['town']).rename(columns=lambda x: 'town_' + str(x))\n",
    "data_henc = pd.concat([data_henc, dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding for flat types\n",
    "dummies = pd.get_dummies(data_henc['flat_type']).rename(columns=lambda x: 'flat_type_' + str(x))\n",
    "data_henc = pd.concat([data_henc, dummies], axis=1)\n",
    "\n",
    "#source: http://www.hdb.gov.sg/cs/infoweb/residential/buying-a-flat/new/types-of-flats&rendermode=preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding for storey ranges\n",
    "dummies = pd.get_dummies(data_henc['storey_range']).rename(columns=lambda x: 'storey_range_' + str(x))\n",
    "data_henc = pd.concat([data_henc, dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding for flat models\n",
    "dummies = pd.get_dummies(data_henc['flat_model']).rename(columns=lambda x: 'flat_model_' + str(x))\n",
    "data_henc = pd.concat([data_henc, dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(761791, 77)\n"
     ]
    }
   ],
   "source": [
    "#remove unnecessary variables\n",
    "data_henc = data_henc.drop('town',1)\n",
    "data_henc = data_henc.drop('flat_type',1)\n",
    "data_henc = data_henc.drop('storey_range',1)\n",
    "data_henc = data_henc.drop('flat_model',1)\n",
    "\n",
    "print(data_henc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales_month</th>\n",
       "      <th>sales_year</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>lease_commence_date</th>\n",
       "      <th>resale_price</th>\n",
       "      <th>town_ANG MO KIO</th>\n",
       "      <th>town_BEDOK</th>\n",
       "      <th>town_BISHAN</th>\n",
       "      <th>town_BUKIT BATOK</th>\n",
       "      <th>town_BUKIT MERAH</th>\n",
       "      <th>...</th>\n",
       "      <th>flat_model_Multi Generation</th>\n",
       "      <th>flat_model_New Generation</th>\n",
       "      <th>flat_model_Premium Apartment</th>\n",
       "      <th>flat_model_Premium Apartment Loft</th>\n",
       "      <th>flat_model_Premium Maisonette</th>\n",
       "      <th>flat_model_Simplified</th>\n",
       "      <th>flat_model_Standard</th>\n",
       "      <th>flat_model_Terrace</th>\n",
       "      <th>flat_model_Type S1</th>\n",
       "      <th>flat_model_Type S2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1977</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1977</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1977</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1977</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1976</td>\n",
       "      <td>47200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sales_month  sales_year  floor_area_sqm  lease_commence_date  resale_price  \\\n",
       "0            1        1990            31.0                 1977        9000.0   \n",
       "1            1        1990            31.0                 1977        6000.0   \n",
       "2            1        1990            31.0                 1977        8000.0   \n",
       "3            1        1990            31.0                 1977        6000.0   \n",
       "4            1        1990            73.0                 1976       47200.0   \n",
       "\n",
       "   town_ANG MO KIO  town_BEDOK  town_BISHAN  town_BUKIT BATOK  \\\n",
       "0                1           0            0                 0   \n",
       "1                1           0            0                 0   \n",
       "2                1           0            0                 0   \n",
       "3                1           0            0                 0   \n",
       "4                1           0            0                 0   \n",
       "\n",
       "   town_BUKIT MERAH         ...          flat_model_Multi Generation  \\\n",
       "0                 0         ...                                    0   \n",
       "1                 0         ...                                    0   \n",
       "2                 0         ...                                    0   \n",
       "3                 0         ...                                    0   \n",
       "4                 0         ...                                    0   \n",
       "\n",
       "   flat_model_New Generation  flat_model_Premium Apartment  \\\n",
       "0                          0                             0   \n",
       "1                          0                             0   \n",
       "2                          0                             0   \n",
       "3                          0                             0   \n",
       "4                          1                             0   \n",
       "\n",
       "   flat_model_Premium Apartment Loft  flat_model_Premium Maisonette  \\\n",
       "0                                  0                              0   \n",
       "1                                  0                              0   \n",
       "2                                  0                              0   \n",
       "3                                  0                              0   \n",
       "4                                  0                              0   \n",
       "\n",
       "   flat_model_Simplified  flat_model_Standard  flat_model_Terrace  \\\n",
       "0                      0                    0                   0   \n",
       "1                      0                    0                   0   \n",
       "2                      0                    0                   0   \n",
       "3                      0                    0                   0   \n",
       "4                      0                    0                   0   \n",
       "\n",
       "   flat_model_Type S1  flat_model_Type S2  \n",
       "0                   0                   0  \n",
       "1                   0                   0  \n",
       "2                   0                   0  \n",
       "3                   0                   0  \n",
       "4                   0                   0  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_henc.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 New Features\n",
    "In this part, we will explore new features that we can add to make our data more valuable. Since the data consists of seven objects, two floats and one integer, the seven objects will be researched and to see which can and will be changed. (Note that adding and dropping variables have been changed to comments, because an error would pop up otherwise. This is because the variable is already added or dropped, thus it cannot be performed again.) <br>\n",
    "\n",
    "***Remaining Lease*** Linear regression will not be able to read the years, since it can see it as another numerical value. Therefore, the remaining lease year is calculated. Once the sales year variable is created, the remaining lease year can be computed by using the following formula: $remaining lease year = 99 - (sales year - lease commence date)$.\n",
    "\n",
    "To check whether the remaining lease variable is correct, the data tail from dataset 5 in the data acquisition is used to compare with the new data. Since only the fifth data set consists of this data, we could use the column for validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that data.copy() is used to make a copy of data, which will be used for analysis\n",
    "data_f = data_henc.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute remaining lease variable\n",
    "if ('remaining_lease' not in data_f.columns):\n",
    "    data_f['remaining_lease'] = 99 - (data.sales_year - data.lease_commence_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Longtitude and Latitude*** Another interesting feature would be the longtitude and latitude of the street name. Fortunately, Google has such a package to make this possible. Unfortunately, this is only possible for 2,500 data points per day. Since we have 768.629 data points, this task was not possible for us. However, we still want to show that we have tried running the code underneath. Note that this can be seen as a limitation for our study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Status code Unknown from https://maps.googleapis.com/maps/api/geocode/json: ERROR - ('Connection aborted.', OSError(\"(32, 'EPIPE')\",))\n"
     ]
    }
   ],
   "source": [
    "#compute longlat variable\n",
    "#data['long_lat'] = geocoder.google(data['street_name']).lating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Area*** Instead of longtitude and latitutde, we have made an extra variable called \"Area\". The Area captures all the town in a specific region, which is based on the information of the official Singapore government site. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that data.copy() is used to make a copy of data, which will be used for analysis\n",
    "data_2f = data_f.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add area variable\n",
    "data_2f.insert(1,'area',(data['town']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area \n",
      "NORTH         213559\n",
      "WEST          191750\n",
      "CENTRAL       158781\n",
      "NORTH EAST    134634\n",
      "EAST           63067\n",
      "Name: area, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#divide towns into areas\n",
    "data_2f['area'][data_2f.area == 'BUKIT MERAH'] = 'CENTRAL'\n",
    "data_2f['area'][data_2f.area == 'TOA PAYOH'] = 'CENTRAL'\n",
    "data_2f['area'][data_2f.area == 'QUEENSTOWN'] = 'CENTRAL'\n",
    "data_2f['area'][data_2f.area == 'GEYLANG'] = 'CENTRAL'\n",
    "data_2f['area'][data_2f.area == 'KALLANG/WHAMPOA'] = 'CENTRAL'\n",
    "data_2f['area'][data_2f.area == 'BISHAN'] = 'CENTRAL'\n",
    "data_2f['area'][data_2f.area == 'MARINE PARADE'] = 'CENTRAL'\n",
    "data_2f['area'][data_2f.area == 'CENTRAL AREA'] = 'CENTRAL'\n",
    "data_2f['area'][data_2f.area == 'BUKIT TIMAH'] = 'CENTRAL'\n",
    "data_2f['area'][data_2f.area == 'TAMPINES'] = 'NORTH'\n",
    "data_2f['area'][data_2f.area == 'YISHUN'] = 'NORTH'\n",
    "data_2f['area'][data_2f.area == 'BEDOK'] = 'NORTH'\n",
    "data_2f['area'][data_2f.area == 'PASIR RIS'] = 'NORTH'\n",
    "data_2f['area'][data_2f.area == 'JURONG WEST'] = 'WEST'\n",
    "data_2f['area'][data_2f.area == 'BUKIT BATOK'] = 'WEST'\n",
    "data_2f['area'][data_2f.area == 'CHOA CHU KANG'] = 'WEST'\n",
    "data_2f['area'][data_2f.area == 'CLEMENTI'] = 'WEST'\n",
    "data_2f['area'][data_2f.area == 'JURONG EAST'] = 'WEST'\n",
    "data_2f['area'][data_2f.area == 'BUKIT PANJANG'] = 'WEST'\n",
    "data_2f['area'][data_2f.area == 'WOODLANDS'] = 'EAST'\n",
    "data_2f['area'][data_2f.area == 'SEMBAWANG'] = 'EAST'\n",
    "data_2f['area'][data_2f.area == 'LIM CHU KANG'] = 'EAST'\n",
    "data_2f['area'][data_2f.area == 'ANG MO KIO'] = 'NORTH EAST'\n",
    "data_2f['area'][data_2f.area == 'HOUGANG'] = 'NORTH EAST'\n",
    "data_2f['area'][data_2f.area == 'SERANGOON'] = 'NORTH EAST'\n",
    "data_2f['area'][data_2f.area == 'SENGKANG'] = 'NORTH EAST'\n",
    "data_2f['area'][data_2f.area == 'PUNGGOL'] = 'NORTH EAST'\n",
    "\n",
    "area_count = data_2f['area'].value_counts()\n",
    "print(\"Area \\n\" +str(area_count))\n",
    "\n",
    "#source: http://www.hdb.gov.sg/cs/infoweb/about-us/history/hdb-towns-your-home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding for area\n",
    "dummies = pd.get_dummies(data_2f['area']).rename(columns=lambda x: 'area_' + str(x))\n",
    "data_2f = pd.concat([data_2f, dummies], axis=1)\n",
    "\n",
    "del data_2f['area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***GDP*** WHY GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales_month</th>\n",
       "      <th>sales_year</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>lease_commence_date</th>\n",
       "      <th>resale_price</th>\n",
       "      <th>town_ANG MO KIO</th>\n",
       "      <th>town_BEDOK</th>\n",
       "      <th>town_BISHAN</th>\n",
       "      <th>town_BUKIT BATOK</th>\n",
       "      <th>town_BUKIT MERAH</th>\n",
       "      <th>...</th>\n",
       "      <th>flat_model_Standard</th>\n",
       "      <th>flat_model_Terrace</th>\n",
       "      <th>flat_model_Type S1</th>\n",
       "      <th>flat_model_Type S2</th>\n",
       "      <th>remaining_lease</th>\n",
       "      <th>area_CENTRAL</th>\n",
       "      <th>area_EAST</th>\n",
       "      <th>area_NORTH</th>\n",
       "      <th>area_NORTH EAST</th>\n",
       "      <th>area_WEST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1977</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1977</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1977</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1977</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1976</td>\n",
       "      <td>47200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sales_month  sales_year  floor_area_sqm  lease_commence_date  resale_price  \\\n",
       "0            1        1990            31.0                 1977        9000.0   \n",
       "1            1        1990            31.0                 1977        6000.0   \n",
       "2            1        1990            31.0                 1977        8000.0   \n",
       "3            1        1990            31.0                 1977        6000.0   \n",
       "4            1        1990            73.0                 1976       47200.0   \n",
       "\n",
       "   town_ANG MO KIO  town_BEDOK  town_BISHAN  town_BUKIT BATOK  \\\n",
       "0                1           0            0                 0   \n",
       "1                1           0            0                 0   \n",
       "2                1           0            0                 0   \n",
       "3                1           0            0                 0   \n",
       "4                1           0            0                 0   \n",
       "\n",
       "   town_BUKIT MERAH    ...      flat_model_Standard  flat_model_Terrace  \\\n",
       "0                 0    ...                        0                   0   \n",
       "1                 0    ...                        0                   0   \n",
       "2                 0    ...                        0                   0   \n",
       "3                 0    ...                        0                   0   \n",
       "4                 0    ...                        0                   0   \n",
       "\n",
       "   flat_model_Type S1  flat_model_Type S2  remaining_lease  area_CENTRAL  \\\n",
       "0                   0                   0               86             0   \n",
       "1                   0                   0               86             0   \n",
       "2                   0                   0               86             0   \n",
       "3                   0                   0               86             0   \n",
       "4                   0                   0               85             0   \n",
       "\n",
       "   area_EAST  area_NORTH  area_NORTH EAST  area_WEST  \n",
       "0          0           0                1          0  \n",
       "1          0           0                1          0  \n",
       "2          0           0                1          0  \n",
       "3          0           0                1          0  \n",
       "4          0           0                1          0  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2f.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Normalizations\n",
    "Data normalization is known as a fundamental preprocessing task to improve the prediction of a model. A normalized dataset might enhances the learning capability with minimum error, since the quality of the data is guaranteed before using any learning algorithm. The data will be scaled in the same range of values for the input features to minize bias [source]. We are using this technique as well to research if this method might improve our scores, since the input are on widely different scales. Two different types of normalization will be used, respectively Z-scoring and Max/Min normalization.\n",
    "\n",
    "[source] S.C. Nayak, B.B. Misra, and H.S. Behera (2016) Impact of Data Normalization on Stock Index Forecasting, p. 257-269 Volume 6 https://pdfs.semanticscholar.org/f412/4953553981e32c39273bb2745a140311d160.pdf\n",
    "\n",
    "#### 3.5.1 Z-scoring\n",
    "Z-scoring normalizes the values of the features according to the mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_z = data_2f.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-scoring\n",
    "data_z[['sales_month', 'sales_year','floor_area_sqm','remaining_lease','lease_commence_date']] = (data_z[['sales_month', 'sales_year', 'floor_area_sqm','remaining_lease','lease_commence_date']] - data_z[['sales_month', 'sales_year', 'floor_area_sqm','remaining_lease','lease_commence_date']].mean())/data_z[['sales_month', 'sales_year', 'floor_area_sqm','remaining_lease','lease_commence_date']].std()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.2 Max/Min-Normalization\n",
    "This method normalizes the values of the features according to the minimum and maximum of these values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_n = data_2f.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max/min\n",
    "data_n[['sales_month', 'sales_year', 'floor_area_sqm','remaining_lease','lease_commence_date']] = (data_n[['sales_month', 'sales_year', 'floor_area_sqm','remaining_lease','lease_commence_date']] - data_n[['sales_month', 'sales_year', 'floor_area_sqm','remaining_lease','lease_commence_date']].min())/(data_n[['sales_month', 'sales_year', 'floor_area_sqm','remaining_lease','lease_commence_date']].max() - data_n[['sales_month', 'sales_year', 'floor_area_sqm','remaining_lease','lease_commence_date']].min())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Additional One Hot Encoding (Discrete Values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_henc_2 = data_2f.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding for sales_year\n",
    "dummies = pd.get_dummies(data_henc_2['sales_year']).rename(columns=lambda x: 'sy_' + str(x))\n",
    "data_henc_2 = pd.concat([data_henc_2, dummies], axis=1)\n",
    "\n",
    "#one hot encoding for sales_month\n",
    "dummies = pd.get_dummies(data_henc_2['sales_month']).rename(columns=lambda x: 'sm_' + str(x))\n",
    "data_henc_2 = pd.concat([data_henc_2, dummies], axis=1)\n",
    "\n",
    "#one hot encoding for lease_commence_date\n",
    "dummies = pd.get_dummies(data_henc_2['lease_commence_date']).rename(columns=lambda x: 'lcd_' + str(x))\n",
    "data_henc_2 = pd.concat([data_henc_2, dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_henc_2 = data_henc_2.drop(columns=['sales_year','sales_month','lease_commence_date'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(761791, 171)\n"
     ]
    }
   ],
   "source": [
    "print(data_henc_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Data Analysis\n",
    "<hr>\n",
    "This part of the report will show algorithms that have been applied to predict the housing prices. We have focused on regressions with different features. This section will first define all the models that will be used and afterwards the results of applying the models to the different scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Models\n",
    "The models below are selected MOTIVATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression\n",
    "Linear regression is one of the most common used modeling technique where the dependent variable is continuous and the independent variables can be either continuous or discrete [source]. Since our dataset has the same setting, this technique is used as one of the possible models.\n",
    "\n",
    "[source] B. Patel, 17 Apr. 2017, Predicting house value using regression analysis, https://towardsdatascience.com/regression-analysis-model-used-in-machine-learning-318f7656108a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "def lin_reg(data):\n",
    "    start = time.time()\n",
    "\n",
    "    data_input = data.drop('resale_price' ,axis=1)\n",
    "    data_output = data['resale_price']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data_input, data_output, test_size=0.33, random_state=42)\n",
    "\n",
    "    model_lin_reg = LinearRegression()\n",
    "    model_lin_reg.fit(x_train, y_train)\n",
    "    y_pred_l = model_lin_reg.predict(x_test)\n",
    "    #y_pred_l_train = model_lin_reg.predict(x_train)\n",
    "    \n",
    "    mae_l = mean_absolute_error(y_test, y_pred_l)\n",
    "    #mae_l_train = mean_absolute_error(y_train, y_pred_l_train)\n",
    "    print(\"\\nMAE for Linear Regression is: %.0f\"%mae_l)\n",
    "    #print(\"For the train set: %.0f\" %mae_l_train)\n",
    "    \n",
    "    cdf_l = r2_score(y_test, y_pred_l)\n",
    "    print('R-squared for Linear Regression: %.2f' % cdf_l)\n",
    "    \n",
    "#    cv_pred = cross_val_predict(model_lin_reg, data_input, data_output, cv=5)\n",
    "#    mae_cv = mean_absolute_error(data_output, cv_pred)\n",
    "#    print(\"\\nCV MAE for LR is: %.0f\"%mae_cv)\n",
    "    \n",
    "    scores = cross_val_score(model_lin_reg, data_input, data_output, cv=5, scoring='neg_mean_absolute_error')\n",
    "    scores = - scores\n",
    "    #print(scores)\n",
    "    print(\"\\nCV MAE: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    print('\\nLR Time = %.0f'%(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest\n",
    "Random Forests are an ensemble method functioning on bagging as mentioned previously. Gradient Boosting Regressors are trees that function on boosting. Boosting is a mechanism in which samples which were not fit well in a tree are given higher probability to be utilized in the next tree. In this way, the algorithm focuses on increasing accuracy of prediction on all samples sequentially. Boosting takes advantage of weak learners and perfects them one by one. Using Gradient Boosting Regressors, the cross-validation accuracy jumped up to 89.80% and the RMSE was down to 0.1297."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Forest Run\n",
    "def random_f(data,version):\n",
    "    start = time.time()\n",
    "    \n",
    "    data_input = data.drop('resale_price' ,axis=1)\n",
    "    data_output = data['resale_price']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data_input, data_output, test_size=0.33, random_state=42)\n",
    "\n",
    "    model_Forest = RandomForestRegressor()\n",
    "    model_Forest.fit(x_train, y_train)\n",
    "    y_pred_f = model_Forest.predict(x_test)\n",
    "    #y_pred_f_train = model_Forest.predict(x_train)\n",
    "    \n",
    "    mae_f = mean_absolute_error(y_test, y_pred_f)\n",
    "    #mae_f_train = mean_absolute_error(y_train, y_pred_f_train)\n",
    "    print(\"\\nMAE for Random Forest is: %.0f\"%mae_f)\n",
    "    #print(\"For the train set: %.0f\" %mae_f_train)\n",
    "    \n",
    "    cdf_f = r2_score(y_test, y_pred_f)\n",
    "    print('R-squared for Random Forest: %.2f' % cdf_f)\n",
    "\n",
    "    if (version == 1):\n",
    "        importances = model_Forest.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        columns = np.array(list(data_input))\n",
    "        return importances\n",
    "        \n",
    "        # Print the feature ranking\n",
    "        print(\"\\nFeature ranking:\")\n",
    "        \n",
    "        for f in range(x_train.shape[1]):\n",
    "            print(\"%d. %s (%f)\" % (f + 1, columns[indices[f]], importances[indices[f]]))\n",
    "        \n",
    "    scores = cross_val_score(model_Forest, data_input, data_output, cv=5, scoring='neg_mean_absolute_error')\n",
    "    scores = - scores\n",
    "    #print(scores)\n",
    "    print(\"\\nCV MAE: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    print('\\nRF Time = %.0f'%(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run AdaBoost\n",
    "def ada(data):\n",
    "    start = time.time()\n",
    "    \n",
    "    data_input = data.drop('resale_price' ,axis=1)\n",
    "    data_output = data['resale_price']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data_input, data_output, test_size=0.33, random_state=42)\n",
    "\n",
    "    model_abr = AdaBoostRegressor()\n",
    "    model_abr.fit(x_train, y_train)\n",
    "    y_pred_abr = model_abr.predict(x_test)\n",
    "    \n",
    "    mae_abr = mean_absolute_error(y_test, y_pred_abr)\n",
    "    print(\"\\nMean Absolute Error for AdaBoost is: %.0f\" %mae_abr)\n",
    "    \n",
    "    cdf_abr = r2_score(y_test, y_pred_abr)\n",
    "    print('R-squared for AdaBoost: %.2f' % cdf_abr)\n",
    " \n",
    "    scores = cross_val_score(model_abr, data_input, data_output, cv=5, scoring='neg_mean_absolute_error')\n",
    "    scores = - scores\n",
    "    #print(scores)\n",
    "    print(\"\\nCV MAE: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    print('\\nAda Time = %.0f'%(time.time() - start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run GradientBoostingRegressor\n",
    "def gbr(data):\n",
    "    start = time.time()\n",
    "    \n",
    "    data_input = data.drop('resale_price' ,axis=1)\n",
    "    data_output = data['resale_price']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data_input, data_output, test_size=0.33, random_state=42)\n",
    "\n",
    "    model_gbr = GradientBoostingRegressor()\n",
    "    model_gbr.fit(x_train, y_train)\n",
    "    y_pred_gbr = model_gbr.predict(x_test)\n",
    "    \n",
    "    mae_gbr = mean_absolute_error(y_test, y_pred_gbr)\n",
    "    print(\"\\nMean Absolute Error for GradientBoostingRegressor is: %.0f\" %mae_gbr) \n",
    "\n",
    "    cdf_gbr = r2_score(y_test, y_pred_gbr)\n",
    "    print('R-squared for GradientBoostingRegressor: %.2f' % cdf_gbr)\n",
    "\n",
    "    scores = cross_val_score(model_gbr, data_input, data_output, cv=5, scoring='neg_mean_absolute_error')\n",
    "    scores = - scores\n",
    "    #print(scores)\n",
    "    print(\"\\nCV MAE: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    print('\\nGBR Time = %.0f'%(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run XG Boost\n",
    "def xg_boost(data):\n",
    "    start = time.time()\n",
    "    \n",
    "    data_input = data.drop('resale_price' ,axis=1)\n",
    "    data_output = data['resale_price']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data_input, data_output, test_size=0.33, random_state=42)\n",
    "    \n",
    "    dtrain = xgb.DMatrix(x_train, label = y_train)\n",
    "    dtest = xgb.DMatrix(x_test, label = y_train)\n",
    "    param = {\n",
    "        'max_depth': 3,  # the maximum depth of each tree. Try with max_depth: 2 to 10.\n",
    "        'eta': 0.3,  # the training step for each iteration. Try with ETA: 0.1, 0.2, 0.3...\n",
    "        'silent': 1,  # logging mode - quiet\n",
    "        'objective': 'reg:linear'}  # defines the loss function to be minimized  \n",
    "    num_round = 20  # the number of training iterations. Try with num_round around few hundred!\n",
    "    #----------------\n",
    "    bst = xgb.train(param, dtrain, num_round)\n",
    "    y_pred_xgb = bst.predict(dtest)\n",
    "    best_preds = np.asarray([np.argmax(line) for line in y_pred_xgb])\n",
    "\n",
    "    mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "    print(\"\\nMean Absolute Error for XGBoost is: %.0f\" %mae_xgb)\n",
    "    #xgb.plot_importance(bst)\n",
    "    #plt.show()\n",
    "\n",
    "    cdf_xgb = r2_score(y_test, y_pred_xgb)\n",
    "    print('R-squared for XGBoost: %.2f' % cdf_xgb)\n",
    "    \n",
    "    scores = cross_val_score(xgb.train, data_input, data_output, cv=5, scoring='neg_mean_absolute_error')\n",
    "    scores = - scores\n",
    "    #print(scores)\n",
    "    print(\"\\nCV MAE: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    print('\\nXGB Time = %.0f'%(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some columns are still of 'object' type and need to be changed to int or float in order to run XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network\n",
    "Predictive Neural Network is a powerful predictive modeling technique, which can learn to perform predictive tasks. It can for example be trained to predict numerical values, such as housing prices. As mentioned in the introduction, previous studies showed that this technique might perform better compared to a regression model. However, since Singapore is a quasi-open market, Neural Network is used to research if this is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "def neural(data):\n",
    "    start = time.time()\n",
    "    \n",
    "    data_input = data.drop('resale_price' ,axis=1)\n",
    "    data_output = data['resale_price']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data_input, data_output, test_size=0.33, random_state=42)\n",
    "\n",
    "    model_n = MLPRegressor()\n",
    "    model_n.fit(x_train, y_train)\n",
    "    y_pred_n = model_n.predict(x_test)\n",
    "    \n",
    "    mae_n = mean_absolute_error(y_test, y_pred_n)\n",
    "    print(\"\\nMean Absolute Error for Neural Network is: %.0f\" %mae_n)  \n",
    "    \n",
    "    cdf_n = r2_score(y_test, y_pred_n)\n",
    "    print('R-squared for Neural Network: %.2f' % cdf_n)\n",
    "    \n",
    "    scores = cross_val_score(model_n, data_input, data_output, cv=5, scoring='neg_mean_absolute_error')\n",
    "    scores = - scores\n",
    "    #print(scores)\n",
    "    print(\"\\nCV MAE: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    print('\\nNeural Time = %.0f'%(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Analysis\n",
    "The analysis section will show the Mean Absolute Error and R-squared of every model with different scenarios. \n",
    "\n",
    "***Mean Absolute Error***\n",
    "MEANING MAE\n",
    "\n",
    "***Coefficient of Determination***\n",
    "The coefficient of determination, also known as $R^2$, is the proportion variance between the dependent variable and the prediction from the independent variable. This coefficient ranges from 0 to 1, where 1 means that there is no variance between the predicted and actual.\n",
    "\n",
    "Formula:<br> \n",
    "$$R^2 = 1 - \\frac{\\sum(y - \\hat{y})^2}{\\sum(y - \\bar{y})^2}$$\n",
    "\n",
    "where $y$ is the actual value, $\\hat{y}$ is the predicted value of y, and $\\bar{y}$ is the mean value of y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scenario 1: Only data encoding\n",
    "Some columns are still of 'object' type and need to be changed to int or float in order to run XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sales_month              int64\n",
      "sales_year               int64\n",
      "town                     int64\n",
      "flat_type                int64\n",
      "storey_range             int64\n",
      "floor_area_sqm         float64\n",
      "flat_model               int64\n",
      "lease_commence_date      int64\n",
      "resale_price           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#print(data_enc.dtypes)\n",
    "data_enc['flat_type'] = pd.to_numeric(data_enc['flat_type'])\n",
    "data_enc['storey_range'] = pd.to_numeric(data_enc['storey_range'])\n",
    "data_enc['flat_model'] = pd.to_numeric(data_enc['flat_model'])\n",
    "data_enc['town'] = pd.to_numeric(data_enc['town'])\n",
    "print(data_enc.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To quickly different algorithms and features, we use a sample size of the full train data.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = data_enc.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MAE for Linear Regression is: 54119\n",
      "R-squared for Linear Regression: 0.73\n",
      "\n",
      "CV MAE: 67015.85 (+/- 39131.44)\n",
      "\n",
      "LR Time = 2\n",
      "\n",
      "MAE for Random Forest is: 16005\n",
      "R-squared for Random Forest: 0.97\n",
      "\n",
      "CV MAE: 57737.25 (+/- 66512.80)\n",
      "\n",
      "RF Time = 144\n"
     ]
    }
   ],
   "source": [
    "lin_reg(data_enc)\n",
    "random_f(data_enc,0)\n",
    "#lin_reg(data_sample)\n",
    "#random_f(data_sample,0)\n",
    "#gbr(data_sample)\n",
    "#xg_boost(data_sample)\n",
    "#neural(data_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scenorio 2: Analysis on one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_sample = data_henc.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MAE for Linear Regression is: 47967\n",
      "R-squared for Linear Regression: 0.80\n",
      "[ 55523.06253656  49459.87404337  43044.16671053  67857.85820959\n",
      "  96245.58648405]\n",
      "\n",
      "CV MAE: 62426.11 (+/- 37573.35)\n",
      "\n",
      "LR Time = 32\n",
      "\n",
      "MAE for Random Forest is: 15874\n",
      "R-squared for Random Forest: 0.97\n",
      "\n",
      "CV MAE: 56892.06 (+/- 65887.97)\n",
      "\n",
      "RF Time = 341\n"
     ]
    }
   ],
   "source": [
    "lin_reg(data_henc)\n",
    "random_f(data_henc,0)\n",
    "#gbr(data_sample)\n",
    "#xg_boost(data_sample)\n",
    "#neural(data_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scenario 3: Analysis on one new feature (remaining lease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_sample = data_f.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MAE for Linear Regression is: 47969\n",
      "R-squared for Linear Regression: 0.80\n",
      "\n",
      "CV MAE: 102928987.60 (+/- 411499977.14)\n",
      "\n",
      "LR Time = 26\n",
      "\n",
      "MAE for Random Forest is: 15854\n",
      "R-squared for Random Forest: 0.97\n",
      "\n",
      "CV MAE: 57203.75 (+/- 67088.86)\n",
      "\n",
      "RF Time = 362\n"
     ]
    }
   ],
   "source": [
    "lin_reg(data_f)\n",
    "random_f(data_f,0)\n",
    "#gbr(data_sample)\n",
    "#xg_boost(data_sample)\n",
    "#neural(data_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scores improved and thus we will keep this feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scenario 4: Analysis on two new features (remaining lease and area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_sample = data_2f.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MAE for Linear Regression is: 47967\n",
      "\n",
      "CV MAE for LR is: 98571776\n",
      "[  5.55347464e+04   4.95112696e+04   4.29991840e+04   6.78804067e+04\n",
      "   4.92643553e+08]\n",
      "\n",
      "CV MAE: 98571895.67 (+/- 394071657.39)\n",
      "\n",
      "LR Time = 50\n",
      "\n",
      "MAE for Random Forrest is: 15738\n",
      "\n",
      "CV MAE: 56892.00 (+/- 67088.69)\n",
      "\n",
      "RF Time = 345\n"
     ]
    }
   ],
   "source": [
    "lin_reg(data_2f)\n",
    "random_f(data_2f,0)\n",
    "#gbr(data_sample)\n",
    "#xg_boost(data_sample)\n",
    "#neural(data_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scenario 5: Analysis on Normalization Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_sample = data_z.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n### z-scoring ###')\n",
    "lin_reg(data_z)\n",
    "random_f(data_z,0)\n",
    "#gbr(data_sample)\n",
    "#xg_boost(data_sample)\n",
    "#neural(data_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scenario 6: Analysis on max-min normalization data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_sample = data_n.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n### max/min ###')\n",
    "lin_reg(data_n)\n",
    "random_f(data_n,0)\n",
    "#gbr(data_sample)\n",
    "#xg_boost(data_sample)\n",
    "#neural(data_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nothing happened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scenario 7: Addition One hot Encoding of Months and Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_sample = data_henc_2.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MAE for Linear Regression is: 29559\n",
      "LR Time = 9\n",
      "\n",
      "MAE for Random Forrest is: 16084\n",
      "RF Time = 145\n"
     ]
    }
   ],
   "source": [
    "lin_reg(data_henc_2)\n",
    "random_f(data_henc_2,0)\n",
    "#gbr(data_sample)\n",
    "#xg_boost(data_sample)\n",
    "#neural(data_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "its horsecrap, will not do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Reduced Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_r = data_2f.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(761791, 83)\n"
     ]
    }
   ],
   "source": [
    "print(data_r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_sample = data_r.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MAE for Random Forest is: 15725\n",
      "R-squared for Random Forest: 0.97\n"
     ]
    }
   ],
   "source": [
    "importances = random_f(data_r,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(761791, 10)\n"
     ]
    }
   ],
   "source": [
    "#indices = np.argsort(importances)[::-1]\n",
    "columns = np.array(list(data_r.drop('resale_price',1)))\n",
    "\n",
    "for i in range(0,len(columns)):\n",
    "    feature = columns[i]\n",
    "    weight = importances[i]\n",
    "    if (weight < 0.005):\n",
    "        del data_r[feature]\n",
    "        \n",
    "print(data_r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MAE for Linear Regression is: 53504\n",
      "R-squared for Linear Regression: 0.75\n",
      "\n",
      "CV MAE for LR is: 67267\n",
      "[  56148.96950623   53980.03231626   49540.52757144   74387.40058907\n",
      "  102306.47657642]\n",
      "\n",
      "CV MAE: 67272.68 (+/- 38913.72)\n",
      "\n",
      "LR Time = 4\n",
      "\n",
      "MAE for Random Forest is: 24652\n",
      "R-squared for Random Forest: 0.93\n",
      "\n",
      "CV MAE: 60318.27 (+/- 63016.36)\n",
      "\n",
      "RF Time = 100\n"
     ]
    }
   ],
   "source": [
    "lin_reg(data_r)\n",
    "random_f(data_r,0)\n",
    "#gbr(data_sample)\n",
    "#xg_boost(data_sample)\n",
    "#neural(data_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- deleting any features with low importance only made the result worse\n",
    "- some overall not important at all but maybe very important for the few datapoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Split Datasets according to Periods\n",
    "\n",
    "Following our assumption in the previous chapter, we also try to run the regressions on seperate datasets to research whether the accuracy will increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the average price per square meter in the sales years, periods can be identified. The first period identified is the economic growth from 1990 until 1997 [13]. The \"Asian Crisis\" of 1997-1998 affected Singapore and other emerging markets, which is visible from the decline in resale price in the data [14]. In the subsequent years, Singapore had a stable growth in economic terms, but coped with the economic slowdown in the US, Japan and the EU. Combined with the SARS outbreak in 2003, the resale prices remained relatively stable until 2007. According to [15], the HDB resale prices from 2007 onwards grew even faster than the private property market. [15] argues that the increase in price is the result of an increase in median income of Singaporeans. \n",
    "\n",
    "\n",
    "Splitting the dataset in these periods could help to predict the resale prices of HDB in Singapore. We thereby assume that the resale prices of data in the first period (i.e. 1990-1997) will be less accurate to predict the resale price in 2018. This is based on both economic motives, as well as demographic motives (e.g. increased population and land mass)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the datasets based on the periods described\n",
    "data_period1 = data_2f.loc[data['sales_year'].isin(['1990','1991','1992','1993','1994','1995','1996','1997','1998'])]\n",
    "data_period2 = data_2f.loc[data['sales_year'].isin(['1999','2000','2001','2002','2003','2004','2005','2006','2007'])]\n",
    "data_period3 = data_2f.loc[data['sales_year'].isin(['2008','2009','2010','2011','2012','2013''2014','2015','2016','2017','2018'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_sample_p1 = data_period1.sample(frac=0.1)\n",
    "#data_sample_p2 = data_period2.sample(frac=0.1)\n",
    "#data_sample_p3 = data_period3.sample(frac=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230238, 83)\n",
      "(309490, 83)\n",
      "(189870, 83)\n"
     ]
    }
   ],
   "source": [
    "periods = [data_period1,data_period2,data_period3]\n",
    "for i in range(0,3):\n",
    "    period = periods[i]\n",
    "    print(period.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### For 1990-1998 ###\n",
      "\n",
      "\n",
      "MAE for Random Forest is: 13959\n",
      "R-squared for Random Forest: 0.98\n",
      "\n",
      "CV MAE: 40205.30 (+/- 12162.30)\n",
      "\n",
      "RF Time = 75\n",
      "\n",
      "### For 1999-2007 ###\n",
      "\n",
      "\n",
      "MAE for Random Forest is: 13129\n",
      "R-squared for Random Forest: 0.96\n",
      "\n",
      "CV MAE: 18904.87 (+/- 6168.79)\n",
      "\n",
      "RF Time = 109\n",
      "\n",
      "### For 2008-2018 ###\n",
      "\n",
      "\n",
      "MAE for Random Forest is: 21179\n",
      "R-squared for Random Forest: 0.94\n",
      "\n",
      "CV MAE: 28331.40 (+/- 5801.44)\n",
      "\n",
      "RF Time = 67\n"
     ]
    }
   ],
   "source": [
    "period_names = ['1990-1998','1999-2007','2008-2018']\n",
    "\n",
    "for i in range(0,3):\n",
    "    print('\\n### For',period_names[i],'###')\n",
    "    period = periods[i]\n",
    "    #lin_reg(period)\n",
    "    random_f(period,0)\n",
    "    #gbr(period)\n",
    "    #xg_boost(period)\n",
    "    #neural(period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Mean Absolute Error: 15462.30\n",
      "Overall R-squared: 0.96\n"
     ]
    }
   ],
   "source": [
    "overall_mae = (13944*230238 + 13119*309490 + 21123*189870)/(230238+309490+189870)\n",
    "print('Overall Mean Absolute Error: %.2f' % overall_mae)\n",
    "\n",
    "overall_rsq = (0.98*230238 + 0.96*309490 + 0.94*189870)/(230238+309490+189870)\n",
    "print('Overall R-squared: %.2f' % overall_rsq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Conclusions, Limitations & Future Research\n",
    "<hr>\n",
    "Add here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "<hr>\n",
    "Add here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
