{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of Singapore HDB Resale Price based on Governmental Data\n",
    "<hr>\n",
    "Thomas ten Hacken, Maxime Kayser and Mei-Jun Yeh <br>\n",
    "CE9010 Introduction to Data Science <br>\n",
    "Singapore, April 2018\n",
    "<hr>\n",
    "## Introduction\n",
    "\n",
    "Predicting housing prices is an extensive researched topic in economics and data science. Previously conducted studies by [4,5,6,8] showed that a neural network is better performing to predict future value than a multiple regression model. This is especially the case for a \"true\" open market [4]. This is contradicted by [7], who argue that results from neural networks vary widely, while traditional regression models are more consistent. Besides predicting prices based on features, novel prediction models have been developed. For example, a price prediction model that looks at the $#$ of searches on Google [9]. Although the researchers found that searches and housing prices are correlated, it is difficult to predict the housing price of a specific building and its characteristics.\n",
    "\n",
    "Studies conducted often work with an extensive list of variables, including features of the house, but also from the environment and the amenities. For example, [10] use variables such as size (in square meters) and age, but also the presence of a garage or swimming pool. \n",
    "\n",
    "### Characteristics of the HDB Property Market\n",
    "In Singapore, a distinction can be made between two types of properties: a private residential market and a market that is managed by the Housing and Development Board (HDB), which is part of the Ministry of National Development [2]. The flats developed in the HDB market are heavily subsidized by the Singaporean government, and are affordable alternatives for Singaporean residents.\n",
    "\n",
    "The market for HDB properties differs from the private residential market in several ways. Firstly, the properties are leased to the residents. This lease period is typically 99 years. After the period, the property ownership rights are again in the hands of HDB. Thus, the owner of an HDB apartment is simply leasing it for an extensive amount of time. This differs from renting, since in that case the tenant needs to pay monthly based on actual market conditions [3]. Besides the lease, the owner can be eligible to rent out or sell the flat during the lease period. This created a new market, bla bla...\n",
    "\n",
    "A previous study conducted in the private residential market [11] shows variables being used in their predictive model. This includes dummy variables for a total of 15 facilities, ranging from swimming pool to security and gyms. The study also took into account unit characteristics, such as size, age and floor level. HDB flats do not have additional facilities, but have similar unit characteristics. The model also takes into account the distance to strategic positions, such as MRT stations and schools.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Objective\n",
    "\n",
    "Since the market is monitored by the Singaporean government, it can be considered as not truly open. Therefore, based on previous research, a regression model might be sufficient. This research aims to validate if a regression model is sufficient for predicting housing prices in the HDB resale market. The HDB resale data from the Singaporean government, spanning from 1990 until January 2018, is used to develop the model.\n",
    "\n",
    "After merging the data, we explore the data, then clean and preprocess the data and finally train the data to predict the test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "<hr>\n",
    "The libraries used are pandas, numpy, seaborn, Counter, matplotlib, axes3d, linearregression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import sklearn\n",
    "from collections import Counter\n",
    "\n",
    "# Visualization\n",
    "%matplotlib inline \n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('png2x','pdf')\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from IPython.display import IFrame\n",
    "\n",
    "# machine learning library\n",
    "from sklearn import datasets, linear_model, cross_validation\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "#import xgboost as xgb\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# other\n",
    "import time\n",
    "\n",
    "pd.options.mode.chained_assignment = None #SettingWithCopyWarning for confusing chained assignment disabled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Data Acquisition\n",
    "<hr>\n",
    "The data for this report is acquired from the Singapore government website [1]. Data are collected from the period 1990 until January 2018. The data is provided in four seperate files, which will be merged into Python. The third file (> 20 MB) was seperated into periods of 2006-2012 and 2012-2014. This was necessary to make use of the Github repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training data = (288144, 10)\n",
      "Number of training data = (197175, 10)\n",
      "Number of training data = (172476, 10)\n",
      "Number of training data = (52203, 10)\n",
      "Number of training data = (58631, 11)\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "data1 = pd.read_csv('sg-resale-flat-prices-1990-1999.csv', sep =',')\n",
    "print('Number of training data =', data1.shape)\n",
    "\n",
    "data2 = pd.read_csv('sg-resale-flat-prices-2000-2005.csv', sep =',')\n",
    "print('Number of training data =', data2.shape)\n",
    "\n",
    "data3 = pd.read_csv('sg-resale-flat-prices-2006-2012.csv', sep =',')\n",
    "print('Number of training data =', data3.shape)\n",
    "\n",
    "data4 = pd.read_csv('sg-resale-flat-prices-2012-2014.csv', sep =',')\n",
    "print('Number of training data =', data4.shape)\n",
    "\n",
    "data5 = pd.read_csv('sg-resale-flat-prices-2014-2018.csv', sep =',')\n",
    "print('Number of training data =', data5.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the shape of the data, there is a noticable difference from the last dataset. To discover which variable has been added to the dataset, we recall the first five features from both the first and the last dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>town</th>\n",
       "      <th>flat_type</th>\n",
       "      <th>block</th>\n",
       "      <th>street_name</th>\n",
       "      <th>storey_range</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>flat_model</th>\n",
       "      <th>lease_commence_date</th>\n",
       "      <th>resale_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>1 ROOM</td>\n",
       "      <td>309</td>\n",
       "      <td>ANG MO KIO AVE 1</td>\n",
       "      <td>10 TO 12</td>\n",
       "      <td>31.0</td>\n",
       "      <td>IMPROVED</td>\n",
       "      <td>1977</td>\n",
       "      <td>9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>1 ROOM</td>\n",
       "      <td>309</td>\n",
       "      <td>ANG MO KIO AVE 1</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>31.0</td>\n",
       "      <td>IMPROVED</td>\n",
       "      <td>1977</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>1 ROOM</td>\n",
       "      <td>309</td>\n",
       "      <td>ANG MO KIO AVE 1</td>\n",
       "      <td>10 TO 12</td>\n",
       "      <td>31.0</td>\n",
       "      <td>IMPROVED</td>\n",
       "      <td>1977</td>\n",
       "      <td>8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>1 ROOM</td>\n",
       "      <td>309</td>\n",
       "      <td>ANG MO KIO AVE 1</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>31.0</td>\n",
       "      <td>IMPROVED</td>\n",
       "      <td>1977</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>216</td>\n",
       "      <td>ANG MO KIO AVE 1</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>73.0</td>\n",
       "      <td>NEW GENERATION</td>\n",
       "      <td>1976</td>\n",
       "      <td>47200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     month        town flat_type block       street_name storey_range  \\\n",
       "0  1990-01  ANG MO KIO    1 ROOM   309  ANG MO KIO AVE 1     10 TO 12   \n",
       "1  1990-01  ANG MO KIO    1 ROOM   309  ANG MO KIO AVE 1     04 TO 06   \n",
       "2  1990-01  ANG MO KIO    1 ROOM   309  ANG MO KIO AVE 1     10 TO 12   \n",
       "3  1990-01  ANG MO KIO    1 ROOM   309  ANG MO KIO AVE 1     07 TO 09   \n",
       "4  1990-01  ANG MO KIO    3 ROOM   216  ANG MO KIO AVE 1     04 TO 06   \n",
       "\n",
       "   floor_area_sqm      flat_model  lease_commence_date  resale_price  \n",
       "0            31.0        IMPROVED                 1977          9000  \n",
       "1            31.0        IMPROVED                 1977          6000  \n",
       "2            31.0        IMPROVED                 1977          8000  \n",
       "3            31.0        IMPROVED                 1977          6000  \n",
       "4            73.0  NEW GENERATION                 1976         47200  "
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show features of data set 1\n",
    "data1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>town</th>\n",
       "      <th>flat_type</th>\n",
       "      <th>block</th>\n",
       "      <th>street_name</th>\n",
       "      <th>storey_range</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>flat_model</th>\n",
       "      <th>lease_commence_date</th>\n",
       "      <th>remaining_lease</th>\n",
       "      <th>resale_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58626</th>\n",
       "      <td>2018-01</td>\n",
       "      <td>YISHUN</td>\n",
       "      <td>5 ROOM</td>\n",
       "      <td>760</td>\n",
       "      <td>YISHUN ST 72</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>122.0</td>\n",
       "      <td>Improved</td>\n",
       "      <td>1987</td>\n",
       "      <td>68</td>\n",
       "      <td>490000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58627</th>\n",
       "      <td>2018-01</td>\n",
       "      <td>YISHUN</td>\n",
       "      <td>5 ROOM</td>\n",
       "      <td>876</td>\n",
       "      <td>YISHUN ST 81</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>121.0</td>\n",
       "      <td>Improved</td>\n",
       "      <td>1987</td>\n",
       "      <td>69</td>\n",
       "      <td>468000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58628</th>\n",
       "      <td>2018-01</td>\n",
       "      <td>YISHUN</td>\n",
       "      <td>EXECUTIVE</td>\n",
       "      <td>792</td>\n",
       "      <td>YISHUN RING RD</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>146.0</td>\n",
       "      <td>Maisonette</td>\n",
       "      <td>1987</td>\n",
       "      <td>68</td>\n",
       "      <td>555000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58629</th>\n",
       "      <td>2018-01</td>\n",
       "      <td>YISHUN</td>\n",
       "      <td>EXECUTIVE</td>\n",
       "      <td>387</td>\n",
       "      <td>YISHUN RING RD</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>146.0</td>\n",
       "      <td>Maisonette</td>\n",
       "      <td>1988</td>\n",
       "      <td>69</td>\n",
       "      <td>550000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58630</th>\n",
       "      <td>2018-01</td>\n",
       "      <td>YISHUN</td>\n",
       "      <td>EXECUTIVE</td>\n",
       "      <td>277</td>\n",
       "      <td>YISHUN ST 22</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>146.0</td>\n",
       "      <td>Maisonette</td>\n",
       "      <td>1985</td>\n",
       "      <td>66</td>\n",
       "      <td>545000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         month    town  flat_type block     street_name storey_range  \\\n",
       "58626  2018-01  YISHUN     5 ROOM   760    YISHUN ST 72     07 TO 09   \n",
       "58627  2018-01  YISHUN     5 ROOM   876    YISHUN ST 81     04 TO 06   \n",
       "58628  2018-01  YISHUN  EXECUTIVE   792  YISHUN RING RD     07 TO 09   \n",
       "58629  2018-01  YISHUN  EXECUTIVE   387  YISHUN RING RD     04 TO 06   \n",
       "58630  2018-01  YISHUN  EXECUTIVE   277    YISHUN ST 22     07 TO 09   \n",
       "\n",
       "       floor_area_sqm  flat_model  lease_commence_date  remaining_lease  \\\n",
       "58626           122.0    Improved                 1987               68   \n",
       "58627           121.0    Improved                 1987               69   \n",
       "58628           146.0  Maisonette                 1987               68   \n",
       "58629           146.0  Maisonette                 1988               69   \n",
       "58630           146.0  Maisonette                 1985               66   \n",
       "\n",
       "       resale_price  \n",
       "58626      490000.0  \n",
       "58627      468000.0  \n",
       "58628      555000.0  \n",
       "58629      550000.0  \n",
       "58630      545000.0  "
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show features of data set 5\n",
    "data5.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By comparing the two data sets, we can see that the extra feature is the remaining lease year of the HBD housing. In Singapore, the lease of the HBD housing starts with 99 years. In the 99 years, the apartment can be resold to someone else, but this does not mean that 99 years will be refreshed. The number of years the previous owner has lived in the apartment will be substracted instead. We believe this is an important feature to consider in the predictive model. Therefore, we will recalculate the row for the other data sets as well during the preprocessing stage. <br>\n",
    "\n",
    "However, before the preprocessing stage, exploration will be done to figure out other possible changes. To continue with the exploration, the data should be merged. To merge the data, the datasets should consist of the same number of features. Therefore, the remaining lease variable will be removed first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training data = (58631, 10)\n"
     ]
    }
   ],
   "source": [
    "data5 = data5.drop('remaining_lease',1)\n",
    "print('Number of training data =', data5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>town</th>\n",
       "      <th>flat_type</th>\n",
       "      <th>block</th>\n",
       "      <th>street_name</th>\n",
       "      <th>storey_range</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>flat_model</th>\n",
       "      <th>lease_commence_date</th>\n",
       "      <th>resale_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>174</td>\n",
       "      <td>ANG MO KIO AVE 4</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Improved</td>\n",
       "      <td>1986</td>\n",
       "      <td>255000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>541</td>\n",
       "      <td>ANG MO KIO AVE 10</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>68.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>1981</td>\n",
       "      <td>275000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>163</td>\n",
       "      <td>ANG MO KIO AVE 4</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>69.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>1980</td>\n",
       "      <td>285000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>446</td>\n",
       "      <td>ANG MO KIO AVE 10</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>68.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>1979</td>\n",
       "      <td>290000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>557</td>\n",
       "      <td>ANG MO KIO AVE 10</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>68.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>1980</td>\n",
       "      <td>290000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     month        town flat_type block        street_name storey_range  \\\n",
       "0  2015-01  ANG MO KIO    3 ROOM   174   ANG MO KIO AVE 4     07 TO 09   \n",
       "1  2015-01  ANG MO KIO    3 ROOM   541  ANG MO KIO AVE 10     01 TO 03   \n",
       "2  2015-01  ANG MO KIO    3 ROOM   163   ANG MO KIO AVE 4     01 TO 03   \n",
       "3  2015-01  ANG MO KIO    3 ROOM   446  ANG MO KIO AVE 10     01 TO 03   \n",
       "4  2015-01  ANG MO KIO    3 ROOM   557  ANG MO KIO AVE 10     07 TO 09   \n",
       "\n",
       "   floor_area_sqm      flat_model  lease_commence_date  resale_price  \n",
       "0            60.0        Improved                 1986      255000.0  \n",
       "1            68.0  New Generation                 1981      275000.0  \n",
       "2            69.0  New Generation                 1980      285000.0  \n",
       "3            68.0  New Generation                 1979      290000.0  \n",
       "4            68.0  New Generation                 1980      290000.0  "
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Merge Datasets\n",
    "Since the data are divided into five datasets, we want to merge the data for further exploration. To do this, the concatenation is used from pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training data = (768629, 10)\n"
     ]
    }
   ],
   "source": [
    "#concatenate dataset\n",
    "sets = [data1, data2, data3, data4, data5]\n",
    "data = pd.concat(sets)\n",
    "print('Number of training data =', data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Cleaning and Preprocessing the Dataset\n",
    "<hr>\n",
    "After exploring the dataset, we came across the following points for preprocessing the data: \n",
    "- The feature month consists of sales year and month, e.g. 1990-01. To include the variable in the model, this variable will be seperated to a variable called sales year and a variable called month. \n",
    "- However, a linear regression will not be able to read the years, since it can see it as another numerical value. Therefore, the remaining lease year is calculated. Once the sales year variable is created, the remaining lease year can be computed by using the following formula: $remaining lease year = 99 - (sales year - lease commence date)$.\n",
    "- Furthermore, there are rows containing characters. These rows (town, flat type, flat model and storey range) are transformed into dummy variables to clarify their levels, with other words, to quantify the qualitative data. <br>\n",
    "\n",
    "### 3.1 Data Cleaning\n",
    "During the exploration, there are some cleaning that should be performed. First, the flat types consist of eight types, which should be seven types instead. The flat type \"Multi Generation\" has a unique value with a space in between and one with a hyphen. Second, the flat models consist of 32 models, which should be 21 instead. This is also because of the capital usage. These doubles are removed by cleaning the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Flat Type Count: 7\n",
      "Flat Type \n",
      "4 ROOM              285136\n",
      "3 ROOM              258482\n",
      "5 ROOM              156260\n",
      "EXECUTIVE            58177\n",
      "2 ROOM                8859\n",
      "1 ROOM                1246\n",
      "MULTI GENERATION       469\n",
      "Name: flat_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None #SettingWithCopyWarning for confusing chained assignment disabled\n",
    "\n",
    "#remove doubles\n",
    "data['flat_type'][data['flat_type'] == 'MULTI-GENERATION'] = 'MULTI GENERATION'\n",
    "\n",
    "#flat_type count\n",
    "count_flat_type = data['flat_type'].nunique()\n",
    "print(\"Total Flat Type Count:\", count_flat_type)\n",
    "flat_type_count = data['flat_type'].value_counts()\n",
    "print(\"Flat Type \\n\" +str(flat_type_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Flat Model Count: 21\n",
      "Flat Model Count \n",
      "Model A                   208633\n",
      "Improved                  202602\n",
      "New Generation            169643\n",
      "Simplified                 51604\n",
      "Standard                   38234\n",
      "Premium Apartment          28886\n",
      "Maisonette                 25136\n",
      "Apartment                  19745\n",
      "Apertment                   9901\n",
      "Model A2                    8382\n",
      "Adjoined flat               1913\n",
      "Model A-Maisonette          1784\n",
      "Terrace                      609\n",
      "DBSS                         601\n",
      "Multi Generation             469\n",
      "Type S1                      183\n",
      "Improved-Maisonette          105\n",
      "Type S2                       80\n",
      "Premium Maisonette            75\n",
      "2-room                        38\n",
      "Premium Apartment Loft         6\n",
      "Name: flat_model, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#remove doubles\n",
    "data['flat_model'][data['flat_model'] == 'MODEL A'] = 'Model A'\n",
    "data['flat_model'][data['flat_model'] == 'IMPROVED'] = 'Improved'\n",
    "data['flat_model'][data['flat_model'] == 'NEW GENERATION'] = 'New Generation'\n",
    "data['flat_model'][data['flat_model'] == 'PREMIUM APARTMENT'] = 'Premium Apartment'\n",
    "data['flat_model'][data['flat_model'] == 'SIMPLIFIED'] = 'Simplified'\n",
    "data['flat_model'][data['flat_model'] == 'STANDARD'] = 'Standard'\n",
    "data['flat_model'][data['flat_model'] == 'APARTMENT'] = 'Apertment'\n",
    "data['flat_model'][data['flat_model'] == 'MAISONETTE'] = 'Maisonette'\n",
    "data['flat_model'][data['flat_model'] == 'ADJOINED FLAT'] = 'Adjoined flat'\n",
    "data['flat_model'][data['flat_model'] == 'MODEL A-MAISONETTE'] = 'Model A-Maisonette'\n",
    "data['flat_model'][data['flat_model'] == 'TERRACE'] = 'Terrace'\n",
    "data['flat_model'][data['flat_model'] == 'MULTI GENERATION'] = 'Multi Generation'\n",
    "data['flat_model'][data['flat_model'] == 'IMPROVED-MAISONETTE'] = 'Improved-Maisonette'\n",
    "data['flat_model'][data['flat_model'] == '2-ROOM'] = '2-room'\n",
    "\n",
    "#flat_model count\n",
    "count_flat_model = data['flat_model'].nunique()\n",
    "print(\"Total Flat Model Count:\", count_flat_model)\n",
    "flat_model_count = data['flat_model'].value_counts()\n",
    "print(\"Flat Model Count \\n\" +str(flat_model_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Storey Range Count: 17\n",
      "Storey Range Count \n",
      "04 TO 06    196169\n",
      "07 TO 09    177012\n",
      "01 TO 03    158446\n",
      "10 TO 12    149470\n",
      "13 TO 15     46780\n",
      "16 TO 18     16906\n",
      "19 TO 21      8337\n",
      "22 TO 24      5233\n",
      "25 TO 27      2100\n",
      "28 TO 30       788\n",
      "34 TO 36       151\n",
      "31 TO 33       151\n",
      "37 TO 39       148\n",
      "40 TO 42        73\n",
      "46 TO 48        11\n",
      "43 TO 45        11\n",
      "49 TO 51         5\n",
      "Name: storey_range, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#remove storey range outliers\n",
    "#data = data.ix[data['storey_range'].isin(['01 TO 05','06 TO 10','11 TO 15','16 TO 20','21 TO 25','26 TO 30','31 TO 35','36 TO 40'])]\n",
    "data = data.loc[data['storey_range'].isin(['01 TO 03','04 TO 06','07 TO 09','10 TO 12','13 TO 15','16 TO 18','19 TO 21','22 TO 24','25 TO 27','28 TO 30','31 TO 33','34 TO 36','37 TO 39','40 TO 42','43 TO 45','46 TO 48','49 TO 51'])]\n",
    "\n",
    "#storey range count\n",
    "count_storey_range = data['storey_range'].nunique()\n",
    "print(\"Total Storey Range Count:\", count_storey_range)\n",
    "storey_range_count = data['storey_range'].value_counts()\n",
    "print(\"Storey Range Count \\n\" +str(storey_range_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add sales year variable\n",
    "if ('sales_year' not in data.columns):\n",
    "    data.insert(1,'sales_year',(pd.DatetimeIndex(data['month']).year))\n",
    "\n",
    "#add sales year variable\n",
    "if ('sales_month' not in data.columns):\n",
    "    data.insert(1,'sales_month',(pd.DatetimeIndex(data['month']).month))\n",
    "    \n",
    "#add sales year variable\n",
    "if ('month' in data.columns):\n",
    "    del data['month']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_enc = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummies for flat types\n",
    "data_enc['flat_type'][data.flat_type == '1 ROOM'] = 1\n",
    "data_enc['flat_type'][data.flat_type == '2 ROOM'] = 2\n",
    "data_enc['flat_type'][data.flat_type == '3 ROOM'] = 3\n",
    "data_enc['flat_type'][data.flat_type == '4 ROOM'] = 4\n",
    "data_enc['flat_type'][data.flat_type == '5 ROOM'] = 5\n",
    "data_enc['flat_type'][data.flat_type == 'MULTI GENERATION'] = 6\n",
    "data_enc['flat_type'][data.flat_type == 'EXECUTIVE'] = 7\n",
    "\n",
    "#flat_type_count = data['flat_type'].value_counts()\n",
    "#print(\"Flat Type \\n\" +str(flat_type_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummies for flat models\n",
    "flat_model_array = np.unique(data['flat_model'])\n",
    "n = len(flat_model_array)\n",
    "\n",
    "for i in range(0,n):\n",
    "    data_enc['flat_model'][data['flat_model'] == flat_model_array[i]] = i+1\n",
    "\n",
    "#count_flat_model = data['flat_model'].nunique()\n",
    "#print(\"Total Flat Model Count:\", count_flat_model)\n",
    "#flat_model_count = data['flat_model'].value_counts()\n",
    "#print(\"Flat Model Count \\n\" +str(flat_model_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummies for storey ranges \n",
    "storey_range_array = np.unique(data['storey_range'])\n",
    "n = len(storey_range_array)\n",
    "\n",
    "for i in range(0,n):\n",
    "    data_enc['storey_range'][data['storey_range'] == storey_range_array[i]] = i+1\n",
    "\n",
    "#count_storey_range = data['storey_range'].nunique()\n",
    "#print(\"Total Storey Range Count:\", count_storey_range)\n",
    "#storey_range_count = data['storey_range'].value_counts()\n",
    "#print(\"Storey Range Count \\n\" +str(storey_range_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummies for town\n",
    "town_array = np.unique(data['town'])\n",
    "n = len(town_array)\n",
    "\n",
    "for i in range(0,n):\n",
    "    data_enc['town'][data['town'] == town_array[i]] = i+1\n",
    "\n",
    "#count_town = data['town'].nunique()\n",
    "#print(\"Total Town Count:\", count_town)\n",
    "#town_count = data['town'].value_counts()\n",
    "#print(\"Town Count \\n\" +str(town_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales_month</th>\n",
       "      <th>sales_year</th>\n",
       "      <th>town</th>\n",
       "      <th>flat_type</th>\n",
       "      <th>block</th>\n",
       "      <th>street_name</th>\n",
       "      <th>storey_range</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>flat_model</th>\n",
       "      <th>lease_commence_date</th>\n",
       "      <th>resale_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>309</td>\n",
       "      <td>ANG MO KIO AVE 1</td>\n",
       "      <td>4</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1977</td>\n",
       "      <td>9000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>309</td>\n",
       "      <td>ANG MO KIO AVE 1</td>\n",
       "      <td>2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1977</td>\n",
       "      <td>6000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>309</td>\n",
       "      <td>ANG MO KIO AVE 1</td>\n",
       "      <td>4</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1977</td>\n",
       "      <td>8000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>309</td>\n",
       "      <td>ANG MO KIO AVE 1</td>\n",
       "      <td>3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1977</td>\n",
       "      <td>6000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>216</td>\n",
       "      <td>ANG MO KIO AVE 1</td>\n",
       "      <td>2</td>\n",
       "      <td>73.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1976</td>\n",
       "      <td>47200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sales_month  sales_year town flat_type block       street_name  \\\n",
       "0            1        1990    1         1   309  ANG MO KIO AVE 1   \n",
       "1            1        1990    1         1   309  ANG MO KIO AVE 1   \n",
       "2            1        1990    1         1   309  ANG MO KIO AVE 1   \n",
       "3            1        1990    1         1   309  ANG MO KIO AVE 1   \n",
       "4            1        1990    1         3   216  ANG MO KIO AVE 1   \n",
       "\n",
       "  storey_range  floor_area_sqm flat_model  lease_commence_date  resale_price  \n",
       "0            4            31.0          6                 1977        9000.0  \n",
       "1            2            31.0          6                 1977        6000.0  \n",
       "2            4            31.0          6                 1977        8000.0  \n",
       "3            3            31.0          6                 1977        6000.0  \n",
       "4            2            73.0         13                 1976       47200.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_enc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that two variables are not going to be used, which are respectively block and street name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove unnecessary variables\n",
    "data_henc = data_henc.drop('block',1)\n",
    "data_henc = data_henc.drop('street_name',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 Test the algorithms\n",
    "!!BE SURE TO RUN THE FUNCTIONS BEFORE!!\n",
    ".....\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some columns are still of 'object' type and need to be changed to int or float in order to run XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sales_month              int64\n",
      "sales_year               int64\n",
      "town                    object\n",
      "flat_type               object\n",
      "block                   object\n",
      "street_name             object\n",
      "storey_range            object\n",
      "floor_area_sqm         float64\n",
      "flat_model              object\n",
      "lease_commence_date      int64\n",
      "resale_price           float64\n",
      "dtype: object\n",
      "sales_month              int64\n",
      "sales_year               int64\n",
      "town                    object\n",
      "flat_type                int64\n",
      "block                   object\n",
      "street_name             object\n",
      "storey_range             int64\n",
      "floor_area_sqm         float64\n",
      "flat_model               int64\n",
      "lease_commence_date      int64\n",
      "resale_price           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data_enc.dtypes)\n",
    "data_enc['flat_type'] = pd.to_numeric(data_enc['flat_type'])\n",
    "data_enc['storey_range'] = pd.to_numeric(data_enc['storey_range'])\n",
    "data_enc['flat_model'] = pd.to_numeric(data_enc['flat_model'])\n",
    "print(data_enc.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To quickly different algorithms and features, we use a sample size of the full train data.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_sample = data_enc.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MAE for Linear Regression is: 54213\n",
      "\n",
      "CV MAE for LR is: 67017\n",
      "[ 54342.59324794  51772.15589677  51043.05756689  76133.48343597\n",
      " 101791.69391596]\n",
      "CV MAE: 67016.60 (+/- 39401.55)\n",
      "LR Time = 3\n",
      "\n",
      "MAE for Random Forrest is: 28674\n",
      "CV MAE: 63052.35 (+/- 58323.71)\n",
      "RF Time = 95\n"
     ]
    }
   ],
   "source": [
    "lin_reg(data_enc)\n",
    "random_f(data_enc,0)\n",
    "#ada(data_sample)\n",
    "#gbr(data_sample)\n",
    "#xg_boost(data_sample)\n",
    "#neural(data_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... results are ok but would be better with hot encoding blablabla .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 One Hot Encoding (Categorical Data)\n",
    "To use the string variables in the linear regression, one hot encoding are used for the following features: town/area, flat type, flat model and storey range. \n",
    "\n",
    "EXPLAIN ONE HOT ENCODING AND MOTIVATION\n",
    "\n",
    "Note that there is a possibility of multicollinearity in the variables when one dummy variable per category is included for categoric variables. This means our model can be errogenous and contains high errors. To avoid this issue, one column per category should be dropped. (drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_henc = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding for flat types\n",
    "dummies = pd.get_dummies(data_henc['flat_type']).rename(columns=lambda x: 'flat_type_' + str(x))\n",
    "data_henc = pd.concat([data_henc, dummies], axis=1)\n",
    "\n",
    "#source: http://www.hdb.gov.sg/cs/infoweb/residential/buying-a-flat/new/types-of-flats&rendermode=preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding for flat models\n",
    "dummies = pd.get_dummies(data_henc['flat_model']).rename(columns=lambda x: 'flat_model_' + str(x))\n",
    "data_henc = pd.concat([data_henc, dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding for storey ranges\n",
    "dummies = pd.get_dummies(data_henc['storey_range']).rename(columns=lambda x: 'storey_range_' + str(x))\n",
    "data_henc = pd.concat([data_henc, dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding for town\n",
    "dummies = pd.get_dummies(data_henc['town']).rename(columns=lambda x: 'town_' + str(x))\n",
    "data_henc = pd.concat([data_henc, dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(761791, 77)\n"
     ]
    }
   ],
   "source": [
    "#remove unnecessary variables\n",
    "data_henc = data_henc.drop('town',1)\n",
    "data_henc = data_henc.drop('flat_type',1)\n",
    "data_henc = data_henc.drop('storey_range',1)\n",
    "data_henc = data_henc.drop('flat_model',1)\n",
    "\n",
    "print(data_henc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.1 Testing the algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_sample = data_henc.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MAE for Linear Regression is: 47967\n",
      "\n",
      "CV MAE for LR is: 80821147992\n",
      "[5.55231440e+04 4.94609489e+04 4.30440728e+04 6.78578582e+04\n",
      " 4.04106055e+11]\n",
      "CV MAE: 80821254085.92 (+/- 323284800457.67)\n",
      "LR Time = 34\n",
      "\n",
      "MAE for Random Forrest is: 15857\n",
      "CV MAE: 57013.50 (+/- 65724.58)\n",
      "RF Time = 285\n"
     ]
    }
   ],
   "source": [
    "lin_reg(data_henc)\n",
    "random_f(data_henc,0)\n",
    "#ada(data_sample)\n",
    "#gbr(data_sample)\n",
    "#xg_boost(data_sample)\n",
    "#neural(data_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 New Features\n",
    "In this part, we will explore new features that we can add to make our data more valuable. Since the data consists of seven objects, two floats and one integer, the seven objects will be researched and to see which can and will be changed. (Note that adding and dropping variables have been changed to comments, because an error would pop up otherwise. This is because the variable is already added or dropped, thus it cannot be performed again.)\n",
    "#### 3.3.1 Remaining Lease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_f = data_henc.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute remaining lease variable\n",
    "if ('remaining_lease' not in data_f.columns):\n",
    "    data_f['remaining_lease'] = 99 - (data.sales_year - data.lease_commence_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_sample = data_f.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MAE for Linear Regression is: 47966\n",
      "\n",
      "CV MAE for LR is: 1483988978\n",
      "[5.55346397e+04 4.95423832e+04 4.30014764e+04 6.77632416e+04\n",
      " 7.41973879e+09]\n",
      "CV MAE: 1483990926.29 (+/- 5935747863.45)\n",
      "LR Time = 32\n",
      "\n",
      "MAE for Random Forrest is: 15897\n",
      "CV MAE: 57329.53 (+/- 67324.44)\n",
      "RF Time = 318\n"
     ]
    }
   ],
   "source": [
    "lin_reg(data_f)\n",
    "random_f(data_f,0)\n",
    "#ada(data_sample)\n",
    "#gbr(data_sample)\n",
    "#xg_boost(data_sample)\n",
    "#neural(data_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scores improved and thus we will keep this feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another interesting feature would be the longtitude and latitude of the street name. Fortunately, Google has such a package to make this possible. Unfortunately, this is only possible for 2,500 data points per day. Since we have 768.629 data points, this task was not possible for us. However, we still want to show that we have tried running the code underneath. Note that this can be seen as a limitation for our study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute longlat variable\n",
    "#data['long_lat'] = geocoder.google(data['street_name']).lating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add area variable\n",
    "data_f.insert(1,'area',(data['town']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area \n",
      "NORTH         213559\n",
      "WEST          191750\n",
      "CENTRAL       158781\n",
      "NORTH EAST    134634\n",
      "EAST           63067\n",
      "Name: area, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#divide towns into areas\n",
    "data_f['area'][data_f.area == 'BUKIT MERAH'] = 'CENTRAL'\n",
    "data_f['area'][data_f.area == 'TOA PAYOH'] = 'CENTRAL'\n",
    "data_f['area'][data_f.area == 'QUEENSTOWN'] = 'CENTRAL'\n",
    "data_f['area'][data_f.area == 'GEYLANG'] = 'CENTRAL'\n",
    "data_f['area'][data_f.area == 'KALLANG/WHAMPOA'] = 'CENTRAL'\n",
    "data_f['area'][data_f.area == 'BISHAN'] = 'CENTRAL'\n",
    "data_f['area'][data_f.area == 'MARINE PARADE'] = 'CENTRAL'\n",
    "data_f['area'][data_f.area == 'CENTRAL AREA'] = 'CENTRAL'\n",
    "data_f['area'][data_f.area == 'BUKIT TIMAH'] = 'CENTRAL'\n",
    "data_f['area'][data_f.area == 'TAMPINES'] = 'NORTH'\n",
    "data_f['area'][data_f.area == 'YISHUN'] = 'NORTH'\n",
    "data_f['area'][data_f.area == 'BEDOK'] = 'NORTH'\n",
    "data_f['area'][data_f.area == 'PASIR RIS'] = 'NORTH'\n",
    "data_f['area'][data_f.area == 'JURONG WEST'] = 'WEST'\n",
    "data_f['area'][data_f.area == 'BUKIT BATOK'] = 'WEST'\n",
    "data_f['area'][data_f.area == 'CHOA CHU KANG'] = 'WEST'\n",
    "data_f['area'][data_f.area == 'CLEMENTI'] = 'WEST'\n",
    "data_f['area'][data_f.area == 'JURONG EAST'] = 'WEST'\n",
    "data_f['area'][data_f.area == 'BUKIT PANJANG'] = 'WEST'\n",
    "data_f['area'][data_f.area == 'WOODLANDS'] = 'EAST'\n",
    "data_f['area'][data_f.area == 'SEMBAWANG'] = 'EAST'\n",
    "data_f['area'][data_f.area == 'LIM CHU KANG'] = 'EAST'\n",
    "data_f['area'][data_f.area == 'ANG MO KIO'] = 'NORTH EAST'\n",
    "data_f['area'][data_f.area == 'HOUGANG'] = 'NORTH EAST'\n",
    "data_f['area'][data_f.area == 'SERANGOON'] = 'NORTH EAST'\n",
    "data_f['area'][data_f.area == 'SENGKANG'] = 'NORTH EAST'\n",
    "data_f['area'][data_f.area == 'PUNGGOL'] = 'NORTH EAST'\n",
    "\n",
    "area_count = data_f['area'].value_counts()\n",
    "print(\"Area \\n\" +str(area_count))\n",
    "\n",
    "#source: http://www.hdb.gov.sg/cs/infoweb/about-us/history/hdb-towns-your-home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding for area\n",
    "dummies = pd.get_dummies(data_f['area']).rename(columns=lambda x: 'area_' + str(x))\n",
    "data_f = pd.concat([data_f, dummies], axis=1)\n",
    "\n",
    "del data_f['area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_sample = data_f.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MAE for Linear Regression is: 47967\n",
      "\n",
      "CV MAE for LR is: 1623803889\n",
      "[5.55406502e+04 4.95154195e+04 4.30006576e+04 6.79226634e+04\n",
      " 8.11881412e+09]\n",
      "CV MAE: 1623806020.78 (+/- 6495008103.76)\n",
      "LR Time = 48\n",
      "\n",
      "MAE for Random Forrest is: 15743\n",
      "Feature ranking:\n",
      "1. sales_year (0.448171)\n",
      "2. floor_area_sqm (0.333070)\n",
      "3. flat_type_4 ROOM (0.061564)\n",
      "4. area_CENTRAL (0.046042)\n",
      "5. flat_type_EXECUTIVE (0.017893)\n",
      "6. lease_commence_date (0.017874)\n",
      "7. sales_month (0.010372)\n",
      "8. flat_type_5 ROOM (0.008035)\n",
      "9. remaining_lease (0.007540)\n",
      "10. area_EAST (0.003468)\n",
      "11. town_CLEMENTI (0.003287)\n",
      "12. town_ANG MO KIO (0.002864)\n",
      "13. storey_range_01 TO 03 (0.002590)\n",
      "14. area_WEST (0.002310)\n",
      "15. town_TAMPINES (0.002223)\n",
      "16. flat_model_Adjoined flat (0.002042)\n",
      "17. town_JURONG WEST (0.001902)\n",
      "18. town_BEDOK (0.001633)\n",
      "19. flat_model_Model A (0.001528)\n",
      "20. storey_range_04 TO 06 (0.001425)\n",
      "21. town_GEYLANG (0.001362)\n",
      "22. town_MARINE PARADE (0.001198)\n",
      "23. town_YISHUN (0.001121)\n",
      "24. town_WOODLANDS (0.001087)\n",
      "25. town_BUKIT BATOK (0.001002)\n",
      "26. storey_range_07 TO 09 (0.000935)\n",
      "27. town_CHOA CHU KANG (0.000932)\n",
      "28. storey_range_10 TO 12 (0.000909)\n",
      "29. flat_model_Terrace (0.000818)\n",
      "30. town_SERANGOON (0.000816)\n",
      "31. flat_model_Improved (0.000792)\n",
      "32. area_NORTH EAST (0.000781)\n",
      "33. town_QUEENSTOWN (0.000775)\n",
      "34. town_TOA PAYOH (0.000742)\n",
      "35. town_CENTRAL AREA (0.000730)\n",
      "36. town_JURONG EAST (0.000653)\n",
      "37. town_BISHAN (0.000630)\n",
      "38. storey_range_13 TO 15 (0.000601)\n",
      "39. town_BUKIT PANJANG (0.000593)\n",
      "40. town_PASIR RIS (0.000551)\n",
      "41. town_KALLANG/WHAMPOA (0.000548)\n",
      "42. flat_model_DBSS (0.000537)\n",
      "43. town_BUKIT MERAH (0.000473)\n",
      "44. area_NORTH (0.000446)\n",
      "45. storey_range_16 TO 18 (0.000428)\n",
      "46. flat_model_New Generation (0.000414)\n",
      "47. town_HOUGANG (0.000412)\n",
      "48. flat_model_Standard (0.000392)\n",
      "49. flat_model_Premium Apartment (0.000387)\n",
      "50. storey_range_19 TO 21 (0.000385)\n",
      "51. storey_range_22 TO 24 (0.000340)\n",
      "52. town_SENGKANG (0.000311)\n",
      "53. flat_type_3 ROOM (0.000311)\n",
      "54. town_BUKIT TIMAH (0.000223)\n",
      "55. flat_model_Simplified (0.000204)\n",
      "56. flat_model_Maisonette (0.000155)\n",
      "57. storey_range_25 TO 27 (0.000153)\n",
      "58. flat_model_Apartment (0.000141)\n",
      "59. flat_model_Type S1 (0.000131)\n",
      "60. storey_range_28 TO 30 (0.000086)\n",
      "61. flat_type_MULTI GENERATION (0.000068)\n",
      "62. town_PUNGGOL (0.000067)\n",
      "63. flat_model_Model A-Maisonette (0.000067)\n",
      "64. flat_model_Apertment (0.000065)\n",
      "65. flat_model_Model A2 (0.000064)\n",
      "66. town_SEMBAWANG (0.000062)\n",
      "67. flat_type_2 ROOM (0.000059)\n",
      "68. flat_model_Multi Generation (0.000058)\n",
      "69. flat_model_Improved-Maisonette (0.000033)\n",
      "70. flat_model_Premium Maisonette (0.000026)\n",
      "71. storey_range_37 TO 39 (0.000019)\n",
      "72. storey_range_40 TO 42 (0.000016)\n",
      "73. flat_model_Type S2 (0.000015)\n",
      "74. flat_type_1 ROOM (0.000012)\n",
      "75. storey_range_34 TO 36 (0.000010)\n",
      "76. storey_range_31 TO 33 (0.000008)\n",
      "77. storey_range_46 TO 48 (0.000004)\n",
      "78. storey_range_43 TO 45 (0.000003)\n",
      "79. flat_model_Premium Apartment Loft (0.000003)\n",
      "80. town_LIM CHU KANG (0.000002)\n",
      "81. storey_range_49 TO 51 (0.000002)\n",
      "82. flat_model_2-room (0.000000)\n"
     ]
    }
   ],
   "source": [
    "lin_reg(data_f)\n",
    "random_f(data_f,1)\n",
    "#ada(data_sample)\n",
    "#gbr(data_sample)\n",
    "#xg_boost(data_sample)\n",
    "#neural(data_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check whether the remaining lease variable is correct, the data tail from dataset 5 in the data acquisition is used to compare with the new data. Since only the fifth data set consists of this data, we could use the column for validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Normalizations\n",
    "#### 3.4.1 Z-scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_z = data_f.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-scoring\n",
    "data_z[['sales_month', 'sales_year','floor_area_sqm','remaining_lease','lease_commence_date']] = (data_z[['sales_month', 'sales_year', 'floor_area_sqm','remaining_lease','lease_commence_date']] - data_z[['sales_month', 'sales_year', 'floor_area_sqm','remaining_lease','lease_commence_date']].mean())/data_z[['sales_month', 'sales_year', 'floor_area_sqm','remaining_lease','lease_commence_date']].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_sample = data_z.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n### z-scoring ###')\n",
    "lin_reg(data_z)\n",
    "random_f(data_z,0)\n",
    "#ada(data_sample)\n",
    "#gbr(data_sample)\n",
    "#xg_boost(data_sample)\n",
    "#neural(data_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2 Max/Min-Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_n = data_f.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max/min\n",
    "data_n[['sales_month', 'sales_year', 'floor_area_sqm','remaining_lease','lease_commence_date']] = (data_n[['sales_month', 'sales_year', 'floor_area_sqm','remaining_lease','lease_commence_date']] - data_n[['sales_month', 'sales_year', 'floor_area_sqm','remaining_lease','lease_commence_date']].min())/(data_n[['sales_month', 'sales_year', 'floor_area_sqm','remaining_lease','lease_commence_date']].max() - data_n[['sales_month', 'sales_year', 'floor_area_sqm','remaining_lease','lease_commence_date']].min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_sample = data_n.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n### max/min ###')\n",
    "lin_reg(data_n)\n",
    "random_f(data_n,0)\n",
    "#ada(data_sample)\n",
    "#gbr(data_sample)\n",
    "#xg_boost(data_sample)\n",
    "#neural(data_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nothing happened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Removing Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_r = data_f.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_sample = data_r.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = random_f(data_r,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices = np.argsort(importances)[::-1]\n",
    "columns = np.array(list(data_r.drop('resale_price',1)))\n",
    "\n",
    "for i in range(0,len(columns)):\n",
    "    feature = columns[i]\n",
    "    weight = importances[i]\n",
    "    if (weight < 0.000026):\n",
    "        del data_r[feature]\n",
    "        \n",
    "print(data_r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg(data_r)\n",
    "random_f(data_r,0)\n",
    "#ada(data_sample)\n",
    "#gbr(data_sample)\n",
    "#xg_boost(data_sample)\n",
    "#neural(data_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- deleting any features with low importance only made the result worse\n",
    "- some overall not important at all but maybe very important for the few datapoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Split Data\n",
    "\n",
    "Following our assumption in the previous chapter, we also try to run the regressions on seperate datasets to research whether the accuracy will increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the average price per square meter in the sales years, periods can be identified. The first period identified is the economic growth from 1990 until 1997 [13]. The \"Asian Crisis\" of 1997-1998 affected Singapore and other emerging markets, which is visible from the decline in resale price in the data [14]. In the subsequent years, Singapore had a stable growth in economic terms, but coped with the economic slowdown in the US, Japan and the EU. Combined with the SARS outbreak in 2003, the resale prices remained relatively stable until 2007. According to [15], the HDB resale prices from 2007 onwards grew even faster than the private property market. [15] argues that the increase in price is the result of an increase in median income of Singaporeans. \n",
    "\n",
    "\n",
    "Splitting the dataset in these periods could help to predict the resale prices of HDB in Singapore. We thereby assume that the resale prices of data in the first period (i.e. 1990-1997) will be less accurate to predict the resale price in 2018. This is based on both economic motives, as well as demographic motives (e.g. increased population and land mass)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the datasets based on the periods described\n",
    "data_period1 = data_f.loc[data['sales_year'].isin(['1990','1991','1992','1993','1994','1995','1996','1997','1998'])]\n",
    "data_period2 = data_f.loc[data['sales_year'].isin(['1999','2000','2001','2002','2003','2004','2005','2006','2007'])]\n",
    "data_period3 = data_f.loc[data['sales_year'].isin(['2008','2009','2010','2011','2012','2013''2014','2015','2016','2017','2018'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_sample_p1 = data_period1.sample(frac=0.1)\n",
    "#data_sample_p2 = data_period2.sample(frac=0.1)\n",
    "#data_sample_p3 = data_period3.sample(frac=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = [data_period1,data_period2,data_period3]\n",
    "for i in range(0,3):\n",
    "    period = periods[i]\n",
    "    print(period.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_names = ['1990-1998','1999-2007','2008-2018']\n",
    "\n",
    "for i in range(0,3):\n",
    "    print('\\n### For',period_names[i],'###\\n')\n",
    "    period = periods[i]\n",
    "    #lin_reg(period)\n",
    "    random_f(period,0)\n",
    "    #ada(period)\n",
    "    #gbr(period)\n",
    "    #xg_boost(period)\n",
    "    #neural(period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall MAE: 15462.29840542326\n"
     ]
    }
   ],
   "source": [
    "overall_mae = (13944*230238 + 13119*309490 + 21123*189870)/(230238+309490+189870)\n",
    "print('Overall MAE:',overall_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Additional Hot Encoding (Discrete Values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_henc_2 = data_f.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding for sales_year\n",
    "dummies = pd.get_dummies(data_henc_2['sales_year']).rename(columns=lambda x: 'sy_' + str(x))\n",
    "data_henc_2 = pd.concat([data_henc_2, dummies], axis=1)\n",
    "\n",
    "#one hot encoding for sales_month\n",
    "dummies = pd.get_dummies(data_henc_2['sales_month']).rename(columns=lambda x: 'sm_' + str(x))\n",
    "data_henc_2 = pd.concat([data_henc_2, dummies], axis=1)\n",
    "\n",
    "#one hot encoding for lease_commence_date\n",
    "dummies = pd.get_dummies(data_henc_2['lease_commence_date']).rename(columns=lambda x: 'lcd_' + str(x))\n",
    "data_henc_2 = pd.concat([data_henc_2, dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_henc_2 = data_henc_2.drop(columns=['sales_year','sales_month','lease_commence_date'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(761791, 171)\n"
     ]
    }
   ],
   "source": [
    "print(data_henc_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_sample = data_henc_2.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MAE for Linear Regression is: 29559\n",
      "LR Time = 9\n",
      "\n",
      "MAE for Random Forrest is: 16084\n",
      "RF Time = 145\n"
     ]
    }
   ],
   "source": [
    "lin_reg(data_henc_2)\n",
    "random_f(data_henc_2,0)\n",
    "#ada(data_sample)\n",
    "#gbr(data_sample)\n",
    "#xg_boost(data_sample)\n",
    "#neural(data_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "its horsecrap, will not do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Data Analysis\n",
    "<hr>\n",
    "This part of the report will show algorithms that have been applied to predict the housing prices. We have focused on regressions with different features. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Forest Run\n",
    "def random_f(data,version):\n",
    "    start = time.time()\n",
    "    \n",
    "    if ('town' in data.columns):\n",
    "        data_input = data.drop(columns=['resale_price','town','street_name','block'],axis=1)\n",
    "    else:\n",
    "        data_input = data.drop('resale_price' ,axis=1)\n",
    "    data_output = data['resale_price']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data_input, data_output, test_size=0.33, random_state=42)\n",
    "\n",
    "    model_Forest = RandomForestRegressor()\n",
    "    model_Forest.fit(x_train, y_train)\n",
    "    y_pred_f = model_Forest.predict(x_test)\n",
    "    #y_pred_f_train = model_Forest.predict(x_train)\n",
    "    \n",
    "    mae_f = mean_absolute_error(y_test, y_pred_f)\n",
    "    #mae_f_train = mean_absolute_error(y_train, y_pred_f_train)\n",
    "\n",
    "    print(\"\\nMAE for Random Forrest is: %.0f\"%mae_f)\n",
    "    #print(\"For the train set: %.0f\" %mae_f_train)\n",
    "\n",
    "    if (version == 1):\n",
    "        \n",
    "        importances = model_Forest.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        columns = np.array(list(data_input))\n",
    "        \n",
    "        # Print the feature ranking\n",
    "        print(\"Feature ranking:\")\n",
    "        \n",
    "        for f in range(x_train.shape[1]):\n",
    "            print(\"%d. %s (%f)\" % (f + 1, columns[indices[f]], importances[indices[f]]))\n",
    "        \n",
    "    scores = cross_val_score(model_Forest, data_input, data_output, cv=5, scoring='neg_mean_absolute_error')\n",
    "    scores = - scores\n",
    "    #print(scores)\n",
    "    print(\"CV MAE: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    print('RF Time = %.0f'%(time.time() - start))\n",
    "    \n",
    "    if (version == 1):\n",
    "        return importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "def lin_reg(data):\n",
    "    start = time.time()\n",
    "    \n",
    "    if ('town' in data.columns):\n",
    "        data_input = data.drop(columns=['resale_price','town','street_name','block'],axis=1)\n",
    "    else:\n",
    "        data_input = data.drop('resale_price' ,axis=1)\n",
    "    data_output = data['resale_price']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data_input, data_output, test_size=0.33, random_state=42)\n",
    "\n",
    "    model_lin_reg = LinearRegression()\n",
    "    model_lin_reg.fit(x_train, y_train)\n",
    "    y_pred_l = model_lin_reg.predict(x_test)\n",
    "    #y_pred_l_train = model_Forest.predict(x_train)\n",
    "    \n",
    "    mae_l = mean_absolute_error(y_test, y_pred_l)\n",
    "    #mae_l_train = mean_absolute_error(y_train, y_pred_l_train)\n",
    "\n",
    "    print(\"\\nMAE for Linear Regression is: %.0f\"%mae_l)\n",
    "    #print(\"For the train set: %.0f\" %mae_l_train)\n",
    "    \n",
    "    cv_pred = cross_val_predict(model_lin_reg, data_input, data_output, cv=5)\n",
    "    mae_cv = mean_absolute_error(data_output, cv_pred)\n",
    "    print(\"\\nCV MAE for LR is: %.0f\"%mae_cv)\n",
    "    \n",
    "    scores = cross_val_score(model_lin_reg, data_input, data_output, cv=5, scoring='neg_mean_absolute_error')\n",
    "    scores = - scores\n",
    "    print(scores)\n",
    "    print(\"CV MAE: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    print('LR Time = %.0f'%(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run AdaBoost\n",
    "def ada(data):\n",
    "    start = time.time()\n",
    "    \n",
    "    if ('town' in data.columns):\n",
    "        data_input = data.drop(columns=['resale_price','town','street_name','block'],axis=1)\n",
    "    else:\n",
    "        data_input = data.drop('resale_price' ,axis=1)\n",
    "    data_output = data['resale_price']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data_input, data_output, test_size=0.33, random_state=42)\n",
    "\n",
    "    model_abr = AdaBoostRegressor()\n",
    "    model_abr.fit(x_train, y_train)\n",
    "    y_pred_abr = model_abr.predict(x_test)\n",
    "    \n",
    "    mae_abr = mean_absolute_error(y_test, y_pred_abr)\n",
    "\n",
    "    print(\"\\nMean Absolute Error for AdaBoost is: %.0f\" %mae_abr)\n",
    "    \n",
    "    scores = cross_val_score(model_abr, data_input, data_output, cv=5, scoring='neg_mean_absolute_error')\n",
    "    scores = - scores\n",
    "    #print(scores)\n",
    "    print(\"CV MAE: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    print('Ada Time = %.0f'%(time.time() - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run GradientBoostingRegressor\n",
    "def gbr(data):\n",
    "    start = time.time()\n",
    "    \n",
    "    if ('town' in data.columns):\n",
    "        data_input = data.drop(columns=['resale_price','town','street_name','block'],axis=1)\n",
    "    else:\n",
    "        data_input = data.drop('resale_price' ,axis=1)\n",
    "    data_output = data['resale_price']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data_input, data_output, test_size=0.33, random_state=42)\n",
    "\n",
    "    model_gbr = GradientBoostingRegressor()\n",
    "    model_gbr.fit(x_train, y_train)\n",
    "    y_pred_gbr = model_gbr.predict(x_test)\n",
    "    \n",
    "    mae_gbr = mean_absolute_error(y_test, y_pred_gbr)\n",
    "\n",
    "    print(\"\\nMean Absolute Error for GradientBoostingRegressor is: %.0f\" %mae_gbr) \n",
    "    \n",
    "    scores = cross_val_score(model_gbr, data_input, data_output, cv=5, scoring='neg_mean_absolute_error')\n",
    "    scores = - scores\n",
    "    #print(scores)\n",
    "    print(\"CV MAE: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    print('GBR Time = %.0f'%(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run XGD Boost\n",
    "def xg_boost(data):\n",
    "    start = time.time()\n",
    "    \n",
    "    if ('town' in data.columns):\n",
    "        data_input = data.drop(columns=['resale_price','town','street_name','block'],axis=1)\n",
    "    else:\n",
    "        data_input = data.drop('resale_price' ,axis=1)\n",
    "    data_output = data['resale_price']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data_input, data_output, test_size=0.33, random_state=42)\n",
    "    \n",
    "    dtrain = xgb.DMatrix(x_train, label = y_train)\n",
    "    dtest = xgb.DMatrix(x_test, label = y_train)\n",
    "    param = {\n",
    "        'max_depth': 3,  # the maximum depth of each tree. Try with max_depth: 2 to 10.\n",
    "        'eta': 0.3,  # the training step for each iteration. Try with ETA: 0.1, 0.2, 0.3...\n",
    "        'silent': 1,  # logging mode - quiet\n",
    "        'objective': 'reg:linear'}  # defines the loss function to be minimized  \n",
    "    num_round = 20  # the number of training iterations. Try with num_round around few hundred!\n",
    "    #----------------\n",
    "    bst = xgb.train(param, dtrain, num_round)\n",
    "    y_pred_xgb = bst.predict(dtest)\n",
    "    best_preds = np.asarray([np.argmax(line) for line in y_pred_xgb])\n",
    "\n",
    "    mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "\n",
    "    print(\"\\nMean Absolute Error for XGBoost is: %.0f\" %mae_xgb)\n",
    "    #xgb.plot_importance(bst)\n",
    "    #plt.show()\n",
    "    \n",
    "    scores = cross_val_score(xgb.train, data_input, data_output, cv=5, scoring='neg_mean_absolute_error')\n",
    "    scores = - scores\n",
    "    #print(scores)\n",
    "    print(\"CV MAE: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    print('XGB Time = %.0f'%(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "def neural(data):\n",
    "    start = time.time()\n",
    "    \n",
    "    if ('town' in data.columns):\n",
    "        data_input = data.drop(columns=['resale_price','town','street_name','block'],axis=1)\n",
    "    else:\n",
    "        data_input = data.drop('resale_price' ,axis=1)\n",
    "    data_output = data['resale_price']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data_input, data_output, test_size=0.33, random_state=42)\n",
    "\n",
    "    model_n = MLPRegressor()\n",
    "    model_n.fit(x_train, y_train)\n",
    "    y_pred_n = model_n.predict(x_test)\n",
    "    \n",
    "    mae_n = mean_absolute_error(y_test, y_pred_n)\n",
    "\n",
    "    print(\"\\nMean Absolute Error for Neural Network is: %.0f\" %mae_n)  \n",
    "    \n",
    "    scores = cross_val_score(model_n, data_input, data_output, cv=5, scoring='neg_mean_absolute_error')\n",
    "    scores = - scores\n",
    "    #print(scores)\n",
    "    print(\"CV MAE: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    print('Neural Time = %.0f'%(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions, Limitations & Future Research\n",
    "<hr>\n",
    "Add here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citations \n",
    "<hr>\n",
    "[1] Retrieved from the Internet: <br />\n",
    "[2] Jiang, L., Phillips, P., & Yu, J. (2014). A new hedonic regression for real estate prices applied to the Singapore residential market. <br />\n",
    "[3] Retrieved from the Internet: https://www.gov.sg/factually/content/do-hdb-flat-buyers-own-their-flat <br />\n",
    "[4] Tay D. P. H. and D. K. H. Ho, 1991, “Artificial Intelligence and The Mass Appraisal of\n",
    "Residential Apartments”, Journal of Property Valuation & Investment, 10(2): 525 – 539. <br />\n",
    "[5] Do A. Q. and G. Grudnitski, 1992, “A Neural Network Approach to Residential Property\n",
    "Appraisal”, The Real Estate Appraiser, 58(3): 38 – 45. <br />\n",
    "[6] McCluskey W., 1996, “Predictive Accuracy of Machine Learning Models for The Mass\n",
    "Appraisal of Residential Property”, New Zealand Valuers’ Journal, July: 41 – 47. <br />\n",
    "[7] Worzala E., M. Lenk and A.Silva, 1995, “An Exploration of Neural Networks and Its\n",
    "Application to Real Estate Valuation”, The Journal of Real Estate Research, 10(2): 185 –\n",
    "201 <br />\n",
    "[8] Limsombunchai, V. (2004, June). House price prediction: hedonic price model vs. artificial neural network. In New Zealand Agricultural and Resource Economics Society Conference (pp. 25-26). <br />\n",
    "[9] Wu, L., & Brynjolfsson, E. (2015). The future of prediction: How Google searches foreshadow housing prices and sales. In Economic analysis of the digital economy (pp. 89-118). University of Chicago Press.<br />\n",
    "[10] Basu, S., & Thibodeau, T. G. (1998). Analysis of spatial autocorrelation in house prices. The Journal of Real Estate Finance and Economics, 17(1), 61-85. <br />\n",
    "[11] Tu, Y., Sun, H., & Yu, S. M. (2007). Spatial autocorrelations and urban housing market segmentation. The Journal of Real Estate Finance and Economics, 34(3), 385-406.<br />\n",
    "[12] From the Internet: http://www.hdb.gov.sg/cs/infoweb/about-us/history/hdb-towns-your-home <br />\n",
    "[13] Johnson, S., Boone, P., Breach, A., & Friedman, E. (2000). Corporate governance in the Asian financial crisis. Journal of financial Economics, 58(1-2), 141-186.<br />\n",
    "[14] Rajan, R. G., & Zingales, L. (1998). Which capitalism? Lessons form the east Asian crisis. Journal of Applied Corporate Finance, 11(3), 40-48. <br />\n",
    "[15] Carol, S., & Sufern, H. (Eds.). (2015). Singapore Perspectives 2015: Choices. World Scientific. <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.5.5"
=======
   "version": "3.6.3"
>>>>>>> 738ca1f0b6cf362a74c2a3792f7adec46b373bcb
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
